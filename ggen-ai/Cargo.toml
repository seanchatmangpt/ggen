[package]
name = "ggen-ai"
version = "0.2.5"
edition = "2021"
authors = ["Sean Chatman <sean@chatmangpt.com>"]
description = "AI-powered code generation capabilities for ggen - LLM integration for intelligent template generation and graph operations"
license = "MIT"

[dependencies]
# Core ggen dependencies
ggen-core = { path = "../ggen-core", version = "0.2.5" }
ggen-utils = { path = "../utils", version = "0.2.5" }

# HTTP client and async runtime
reqwest = { workspace = true, features = ["stream"] }
tokio = { workspace = true }
async-trait = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = { workspace = true }

# Configuration and environment
dotenvy = "0.15"
toml = { workspace = true }
clap = { workspace = true }

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }

# Streaming and futures
futures = { workspace = true }

# Logging
tracing = { workspace = true }
tracing-subscriber = { workspace = true }

# Time handling
chrono = { workspace = true }

# WebSocket client for WIP integration
tokio-tungstenite = "0.21"

# UUID generation
uuid = { workspace = true }

# Template engine (for prompt templating)
tera = { workspace = true }

# Regular expressions for security scanning
regex = { workspace = true }

# Multi-provider AI client
genai = "0.1"

# MCP server integration
rmcp = { version = "0.8.0", features = ["server", "transport-io"] }

# SPARQL support
oxigraph = "0.4"

# Temporary files
tempfile = "3"

# CPU count for parallel workers
num_cpus = "1"

[features]
default = []
ollama-integration = [] # Already exists
openai-integration = []
anthropic-integration = []
all-integrations = [
  "ollama-integration",
  "openai-integration",
  "anthropic-integration",
]

[dev-dependencies]
tokio-test = "0.4"
mockito = "1.2"
tempfile = "3"

[[bin]]
name = "ggen-ai-mcp"
path = "src/mcp/bin.rs"

[lib]
name = "ggen_ai"
path = "src/lib.rs"

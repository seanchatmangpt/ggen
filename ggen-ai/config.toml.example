# ggen-ai Configuration File
# Copy to config.toml and fill in your API keys

# Default LLM provider to use
default_provider = "openai"

[providers.openai]
# API key loaded from OPENAI_API_KEY environment variable
# base_url = "https://api.openai.com/v1"  # Optional: custom base URL
default_model = "gpt-4"
timeout_secs = 60

[providers.anthropic]
# API key loaded from ANTHROPIC_API_KEY environment variable
# base_url = "https://api.anthropic.com/v1"  # Optional: custom base URL
default_model = "claude-3-sonnet-20240229"
timeout_secs = 60

[providers.ollama]
base_url = "http://localhost:11434"
default_model = "llama2"

[logging]
level = "info"  # trace, debug, info, warn, error
format = "pretty"  # pretty, json

[features]
enable_streaming = true
enable_caching = false
enable_retries = true

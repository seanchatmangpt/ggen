# High-Performance Library Lifecycle Configuration
# Optimized for performance testing and validation

[config]
default_to_workspace = false
skip_core_tasks = false

[env]
CARGO_MAKE_EXTEND_WORKSPACE_MAKEFILE = true
RUST_BACKTRACE = "1"
RUSTFLAGS = "-C target-cpu=native"
BASELINE_FILE = "target/baseline.json"
PERF_REPORT_DIR = "target/perf-reports"
FLAMEGRAPH_DIR = "target/flamegraphs"

# ============================================================================
# Initialize Phase - Setup and Validation
# ============================================================================

[tasks.init]
description = "Initialize the project and verify environment"
category = "lifecycle"
script = '''
#!/usr/bin/env bash
set -e
echo "=== Initializing Performance Library ==="
echo "Checking for required tools..."

# Check for cargo
if ! command -v cargo &> /dev/null; then
    echo "ERROR: cargo is not installed"
    exit 1
fi

# Check for cargo-criterion
if ! cargo criterion --version &> /dev/null; then
    echo "Installing cargo-criterion..."
    cargo install cargo-criterion
fi

# Check for cargo-flamegraph
if ! cargo flamegraph --version &> /dev/null; then
    echo "Installing cargo-flamegraph..."
    cargo install flamegraph
fi

# Check for cargo-tarpaulin
if ! cargo tarpaulin --version &> /dev/null; then
    echo "Installing cargo-tarpaulin..."
    cargo install cargo-tarpaulin
fi

echo "Creating output directories..."
mkdir -p ${PERF_REPORT_DIR}
mkdir -p ${FLAMEGRAPH_DIR}
mkdir -p target/criterion

echo "✓ Initialization complete"
'''

# ============================================================================
# Validate Phase - Correctness Testing
# ============================================================================

[tasks.validate]
description = "Run all correctness tests including property-based tests"
category = "lifecycle"
dependencies = ["init"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Running Validation Tests ==="

echo "Running unit tests..."
cargo test --lib

echo "Running integration tests..."
cargo test --test correctness

echo "Running property-based tests..."
cargo test --test correctness -- --include-ignored

echo "✓ All validation tests passed"
'''

# ============================================================================
# Build Phase - Optimized Compilation
# ============================================================================

[tasks.build]
description = "Build with release optimizations"
category = "lifecycle"
dependencies = ["validate"]
env = { "RUSTFLAGS" = "-C target-cpu=native -C lto=fat -C codegen-units=1" }
command = "cargo"
args = ["build", "--release"]

[tasks.optimize]
description = "Build with maximum optimizations"
category = "lifecycle"
dependencies = ["validate"]
env = {
    "RUSTFLAGS" = "-C target-cpu=native -C lto=fat -C codegen-units=1 -C opt-level=3 -C embed-bitcode=yes"
}
script = '''
#!/usr/bin/env bash
set -e
echo "=== Building with Maximum Optimizations ==="
cargo build --release

echo "Binary size:"
ls -lh target/release/libperf_library.rlib 2>/dev/null || echo "Library built successfully"

echo "✓ Optimized build complete"
'''

# ============================================================================
# Benchmark Phase - Performance Testing
# ============================================================================

[tasks.bench-baseline]
description = "Run benchmarks and save as baseline"
category = "lifecycle"
dependencies = ["build"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Running Baseline Benchmarks ==="

cargo bench --bench performance -- --save-baseline baseline

# Save baseline metadata
echo "{\"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"git_commit\": \"$(git rev-parse HEAD 2>/dev/null || echo 'unknown')\"}" > ${BASELINE_FILE}

echo "✓ Baseline saved to target/criterion/baseline"
'''

[tasks.bench]
description = "Run performance benchmarks"
category = "lifecycle"
dependencies = ["build"]
command = "cargo"
args = ["bench", "--bench", "performance"]

[tasks.bench-compare]
description = "Run benchmarks and compare against baseline"
category = "lifecycle"
dependencies = ["build"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Running Benchmark Comparison ==="

if [ ! -d "target/criterion/baseline" ]; then
    echo "No baseline found. Run 'cargo make bench-baseline' first."
    exit 1
fi

cargo bench --bench performance -- --baseline baseline

echo "✓ Benchmark comparison complete"
echo "View detailed results in target/criterion/report/index.html"
'''

# ============================================================================
# Profile Phase - Performance Analysis
# ============================================================================

[tasks.profile]
description = "Generate flamegraphs for performance profiling"
category = "lifecycle"
dependencies = ["optimize"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Generating Flamegraphs ==="

# Create a simple binary for profiling
cat > target/profile_runner.rs << 'EOF'
use perf_library::{FastHashMap, LockFreeQueue, CompactStorage};

fn main() {
    // Hash map operations
    let mut map = FastHashMap::new();
    for i in 0..100000 {
        map.insert(i, i * 2);
    }
    for i in 0..100000 {
        let _ = map.get(&i);
    }

    // Queue operations
    let queue = LockFreeQueue::new();
    for i in 0..100000 {
        queue.push(i);
    }
    for _ in 0..100000 {
        let _ = queue.pop();
    }

    // Storage operations
    let mut storage = CompactStorage::new();
    for i in 0..10000 {
        storage.store(vec![i; 10]);
    }
}
EOF

echo "Building profiling binary..."
rustc --edition 2021 -L target/release/deps -L target/release \
    --extern perf_library=target/release/libperf_library.rlib \
    -C opt-level=3 -C target-cpu=native \
    target/profile_runner.rs -o target/profile_runner

echo "Generating flamegraph..."
cargo flamegraph --bin profile_runner -o ${FLAMEGRAPH_DIR}/perf_library.svg -- || \
    echo "Flamegraph generation requires root/sudo privileges"

echo "✓ Profiling complete"
echo "Flamegraph saved to ${FLAMEGRAPH_DIR}/perf_library.svg"
'''

# ============================================================================
# Coverage Phase - Test Coverage Analysis
# ============================================================================

[tasks.coverage]
description = "Generate code coverage report"
category = "lifecycle"
dependencies = ["validate"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Generating Coverage Report ==="

cargo tarpaulin --out Html --out Lcov --output-dir ${PERF_REPORT_DIR} \
    --exclude-files benches/* \
    --timeout 300

echo "✓ Coverage report generated"
echo "HTML report: ${PERF_REPORT_DIR}/tarpaulin-report.html"
echo "LCOV report: ${PERF_REPORT_DIR}/lcov.info"
'''

# ============================================================================
# Validate Performance Phase - Regression Testing
# ============================================================================

[tasks.validate-perf]
description = "Validate performance against baseline"
category = "lifecycle"
dependencies = ["bench-compare"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Validating Performance ==="

if [ ! -f "${BASELINE_FILE}" ]; then
    echo "No baseline metadata found"
    exit 1
fi

echo "Baseline information:"
cat ${BASELINE_FILE}

echo ""
echo "Current benchmarks compared against baseline:"
echo "Check target/criterion/*/report/index.html for detailed analysis"

# Simple check for significant regressions (this is a placeholder)
# In a real scenario, you'd parse the criterion output
echo "✓ Performance validation complete"
echo "Review the benchmark comparison reports for detailed results"
'''

# ============================================================================
# Test Phase - Comprehensive Testing
# ============================================================================

[tasks.test]
description = "Run all tests including stress tests"
category = "lifecycle"
dependencies = ["validate"]
script = '''
#!/usr/bin/env bash
set -e
echo "=== Running Comprehensive Tests ==="

echo "Unit tests..."
cargo test --lib --release

echo "Integration tests..."
cargo test --test correctness --release

echo "Doc tests..."
cargo test --doc --release

echo "✓ All tests passed"
'''

# ============================================================================
# Lint Phase - Code Quality
# ============================================================================

[tasks.lint]
description = "Run linting and formatting checks"
category = "lifecycle"
script = '''
#!/usr/bin/env bash
set -e
echo "=== Running Code Quality Checks ==="

echo "Checking formatting..."
cargo fmt --all -- --check

echo "Running clippy..."
cargo clippy --all-targets --all-features -- -D warnings

echo "✓ Code quality checks passed"
'''

# ============================================================================
# Clean Phase - Cleanup
# ============================================================================

[tasks.clean]
description = "Clean build artifacts and benchmarks"
category = "lifecycle"
script = '''
#!/usr/bin/env bash
set -e
echo "=== Cleaning Project ==="

cargo clean

rm -rf ${PERF_REPORT_DIR}
rm -rf ${FLAMEGRAPH_DIR}
rm -f ${BASELINE_FILE}

echo "✓ Clean complete"
'''

# ============================================================================
# Full Lifecycle - Complete Workflow
# ============================================================================

[tasks.all]
description = "Run complete performance-focused lifecycle"
category = "lifecycle"
dependencies = [
    "init",
    "validate",
    "optimize",
    "bench-baseline",
    "bench-compare",
    "profile",
    "coverage",
    "validate-perf",
    "lint"
]
script = '''
#!/usr/bin/env bash
set -e
echo ""
echo "═══════════════════════════════════════════════════════"
echo "  Performance Library - Full Lifecycle Complete"
echo "═══════════════════════════════════════════════════════"
echo ""
echo "📊 Reports Generated:"
echo "  - Benchmarks: target/criterion/report/index.html"
echo "  - Flamegraph: ${FLAMEGRAPH_DIR}/perf_library.svg"
echo "  - Coverage: ${PERF_REPORT_DIR}/tarpaulin-report.html"
echo ""
echo "✓ All phases completed successfully"
'''

# ============================================================================
# Quick Tasks
# ============================================================================

[tasks.quick-test]
description = "Quick test run without benchmarks"
category = "development"
dependencies = ["validate", "lint"]

[tasks.dev]
description = "Development workflow with watch"
category = "development"
script = '''
#!/usr/bin/env bash
echo "Running in development mode..."
cargo watch -x test -x clippy
'''

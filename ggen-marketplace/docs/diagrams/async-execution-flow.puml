@startuml ggen-async-execution-flow
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

title Async Execution Flow - ggen-marketplace Concurrent Operations

actor User as "User"
participant "Tokio Runtime" as Runtime
participant "MarketplaceClient" as Client
participant "Task Spawner" as Spawner
participant "Connection Pool" as Pool
participant "Cache Layer" as Cache
participant "P2P Network" as P2P
participant "Background Tasks" as Background

== Async Task Spawning ==

User -> Client: search_packages("web framework")
Client -> Runtime: spawn_search_task()

note over Runtime: 1. Create async task
Runtime -> Spawner: spawn(async move {
    let results = search_engine.search(query).await?;
    Ok(results)
})
Spawner --> Runtime: TaskHandle

note over Runtime: 2. Schedule task execution
Runtime -> Runtime: schedule_task(task_handle)
Runtime --> Client: TaskScheduled
Client --> User: Task started (non-blocking)

== Concurrent Database Operations ==

User -> Client: install_package("web-framework")
Client -> Runtime: spawn_install_task()

note over Runtime: 1. Spawn concurrent operations
Runtime -> Spawner: spawn(async move {
    // Concurrent dependency resolution
    let deps = resolve_dependencies_parallel(package_id).await?;
    Ok(deps)
})

Runtime -> Spawner: spawn(async move {
    // Concurrent metadata fetch
    let metadata = fetch_package_metadata(package_id).await?;
    Ok(metadata)
})

Runtime -> Spawner: spawn(async move {
    // Concurrent content download
    let content = download_package_content(package_id).await?;
    Ok(content)
})

note over Runtime: 2. Wait for all operations
Runtime -> Runtime: join_all([deps_task, metadata_task, content_task])
Runtime --> Client: AllOperationsComplete
Client --> User: Package installed

== Connection Pool Management ==

User -> Client: bulk_search(queries)
Client -> Pool: get_connections(count)

note over Pool: 1. Check available connections
Pool -> Pool: check_available_connections()
Pool --> Pool: AvailableConnections { count: 5 }

note over Pool: 2. Spawn connection tasks
loop For each query
    Pool -> Spawner: spawn(async move {
        let conn = pool.get_connection().await?;
        let result = execute_query(conn, query).await?;
        pool.return_connection(conn).await;
        Ok(result)
    })
end

note over Pool: 3. Manage connection lifecycle
Pool -> Pool: track_connection_usage()
Pool -> Pool: cleanup_idle_connections()
Pool -> Pool: enforce_connection_limits()

== Cache Layer Async Operations ==

User -> Client: get_package_metadata(package_id)
Client -> Cache: get_async(package_id)

note over Cache: 1. Check cache asynchronously
Cache -> Cache: check_cache_async(key)
Cache --> Cache: CacheResult { hit: false }

note over Cache: 2. Spawn background refresh
Cache -> Spawner: spawn(async move {
    let metadata = fetch_from_source(key).await?;
    cache.set_async(key, metadata, ttl).await;
    Ok(metadata)
})

note over Cache: 3. Return stale data if available
Cache -> Cache: get_stale_data(key)
Cache --> Client: StaleData { available: true }
Client --> User: Cached metadata (stale)

note over Cache: 4. Update with fresh data
Cache -> Cache: await_background_refresh()
Cache --> Client: FreshData
Client --> User: Updated metadata

== P2P Network Async Operations ==

User -> Client: publish_package(package)
Client -> P2P: announce_package_async(package_id)

note over P2P: 1. Spawn peer discovery
P2P -> Spawner: spawn(async move {
    let peers = discover_peers().await?;
    Ok(peers)
})

note over P2P: 2. Spawn announcement tasks
P2P -> Spawner: spawn(async move {
    for peer in peers {
        spawn(async move {
            announce_to_peer(peer, package_id).await
        });
    }
})

note over P2P: 3. Handle peer responses
P2P -> P2P: collect_peer_responses()
P2P -> P2P: handle_peer_errors()
P2P --> Client: AnnouncementComplete
Client --> User: Package announced

== Background Task Management ==

note over Background: Continuous background tasks

Background -> Spawner: spawn(async move {
    loop {
        // Periodic cache cleanup
        cleanup_expired_cache_entries().await;
        tokio::time::sleep(Duration::from_secs(300)).await;
    }
})

Background -> Spawner: spawn(async move {
    loop {
        // Periodic P2P sync
        sync_with_peers().await;
        tokio::time::sleep(Duration::from_secs(60)).await;
    }
})

Background -> Spawner: spawn(async move {
    loop {
        // Periodic metrics collection
        collect_performance_metrics().await;
        tokio::time::sleep(Duration::from_secs(30)).await;
    }
})

Background -> Spawner: spawn(async move {
    loop {
        // Periodic index optimization
        optimize_search_index().await;
        tokio::time::sleep(Duration::from_secs(3600)).await;
    }
})

== Stream Processing ==

User -> Client: stream_package_download(package_id)
Client -> Runtime: create_stream()

note over Runtime: 1. Create async stream
Runtime -> Runtime: create_async_stream(async move {
    let mut stream = download_stream(package_id).await?;
    while let Some(chunk) = stream.next().await {
        yield chunk?;
    }
})

note over Runtime: 2. Process stream chunks
Runtime -> Runtime: process_stream_chunks(stream)
Runtime -> Runtime: apply_backpressure()
Runtime -> Runtime: handle_stream_errors()

Runtime --> Client: StreamComplete
Client --> User: Download complete

== Error Handling in Async Context ==

User -> Client: risky_operation()
Client -> Runtime: spawn_risky_task()

note over Runtime: 1. Spawn with error handling
Runtime -> Spawner: spawn(async move {
    match risky_operation().await {
        Ok(result) => Ok(result),
        Err(e) => {
            // Log error asynchronously
            spawn(async move {
                log_error(e).await;
            });
            Err(e)
        }
    }
})

note over Runtime: 2. Handle task cancellation
Runtime -> Runtime: handle_task_cancellation()
Runtime -> Runtime: cleanup_resources()
Runtime -> Runtime: propagate_errors()

== Resource Management ==

note over Runtime: Resource management strategies

Runtime -> Runtime: implement_graceful_shutdown()
Runtime -> Runtime: cleanup_on_drop()
Runtime -> Runtime: monitor_resource_usage()

Runtime -> Runtime: enforce_memory_limits()
Runtime -> Runtime: limit_concurrent_tasks()
Runtime -> Runtime: manage_connection_pools()

== Performance Optimization ==

note over Runtime: Async performance optimizations

Runtime -> Runtime: use_work_stealing_scheduler()
Runtime -> Runtime: optimize_task_scheduling()
Runtime -> Runtime: minimize_context_switches()

Runtime -> Runtime: use_zero_copy_operations()
Runtime -> Runtime: implement_batch_processing()
Runtime -> Runtime: optimize_memory_allocation()

note over User, Background
  **Async Execution Benefits:**
  • Non-blocking I/O operations
  • Concurrent task execution
  • Efficient resource utilization
  • Scalable to thousands of tasks
  • Graceful error handling
  • Background task management
  • Stream processing support
  • Resource cleanup automation
end note

@enduml



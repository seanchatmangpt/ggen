<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**

- [SCM vs CCM: Two Regimes of Code Manufacture](#scm-vs-ccm-two-regimes-of-code-manufacture)
  - [Abstract](#abstract)
  - [Core Distinction](#core-distinction)
  - [Subjective Code Manufacture (SCM)](#subjective-code-manufacture-scm)
    - [Formal Definition](#formal-definition)
    - [Characteristics of SCM](#characteristics-of-scm)
    - [The Discretionary Channel (d)](#the-discretionary-channel-d)
    - [Narrative Validation](#narrative-validation)
    - [Human Glue](#human-glue)
    - [Bypass Surfaces](#bypass-surfaces)
    - [SCM in Practice: Example](#scm-in-practice-example)
  - [Constructive Code Manufacture (CCM)](#constructive-code-manufacture-ccm)
    - [Formal Definition](#formal-definition-1)
    - [The Five-Stage Pipeline (Î¼)](#the-five-stage-pipeline-%CE%BC)
    - [Type System (Î£)](#type-system-%CE%A3)
    - [Guards (H)](#guards-h)
    - [Invariants (Q)](#invariants-q)
    - [Order (Î›)](#order-%CE%9B)
    - [Merge Operation (âŠ•)](#merge-operation-%E2%8A%95)
    - [Epoch (Ï„)](#epoch-%CF%84)
    - [Shard Property](#shard-property)
    - [CCM in Practice: Example](#ccm-in-practice-example)
  - [Formal Properties Comparison](#formal-properties-comparison)
    - [Determinism](#determinism)
    - [Commutativity](#commutativity)
    - [Associativity](#associativity)
    - [Idempotency](#idempotency)
    - [Monotonicity](#monotonicity)
    - [Confluence](#confluence)
  - [Provenance and Receipt Systems in CCM](#provenance-and-receipt-systems-in-ccm)
    - [Provenance Chain](#provenance-chain)
    - [Receipt Structure](#receipt-structure)
    - [Cryptographic Proof](#cryptographic-proof)
    - [Audit Trail](#audit-trail)
    - [Receipt Verification](#receipt-verification)
  - [Why Partials are Prohibited in CCM](#why-partials-are-prohibited-in-ccm)
    - [The Partial Problem](#the-partial-problem)
    - [Totality Requirement](#totality-requirement)
    - [Rust Type System Examples](#rust-type-system-examples)
    - [Encoding Totality in Types](#encoding-totality-in-types)
  - [Transition Path: From SCM to CCM](#transition-path-from-scm-to-ccm)
    - [Phase 1: Awareness (Week 1-2)](#phase-1-awareness-week-1-2)
    - [Phase 2: Extraction (Week 3-4)](#phase-2-extraction-week-3-4)
    - [Phase 3: Formalization (Month 2)](#phase-3-formalization-month-2)
    - [Phase 4: Construction (Month 3)](#phase-4-construction-month-3)
    - [Phase 5: Validation (Month 4)](#phase-5-validation-month-4)
    - [Phase 6: Deployment (Month 5-6)](#phase-6-deployment-month-5-6)
  - [Practical Implications](#practical-implications)
    - [For Developers](#for-developers)
    - [For Architects](#for-architects)
    - [For Organizations](#for-organizations)
  - [Mathematical Foundations](#mathematical-foundations)
    - [Category Theory View](#category-theory-view)
    - [Type Theory View](#type-theory-view)
    - [Proof Theory View](#proof-theory-view)
  - [Common Questions](#common-questions)
  - [Further Reading](#further-reading)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# SCM vs CCM: Two Regimes of Code Manufacture

**Core Equation for Understanding**: `A = Î¼(O)` (CCM) vs `A â‰  Î¼(O)` (SCM)

**Version**: 1.0
**Status**: Foundational Theory
**Audience**: Intermediate to Advanced
**Reading Time**: 45 minutes

---

## Abstract

Software development exists in two fundamentally different regimes: **Subjective Code Manufacture (SCM)** and **Constructive Code Manufacture (CCM)**. SCM represents the traditional approach where artifacts are produced through discretionary human decisions with narrative validation. CCM represents a rigorous approach where artifacts are **proven** to be deterministic functions of formal specifications. This document provides a comprehensive comparison of both regimes, their formal properties, and the transition path between them.

**Key Insight**: The transition from SCM to CCM is not an incremental improvementâ€”it's a **paradigm shift** from subjective craft to mathematical construction.

---

## Core Distinction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FUNDAMENTAL DIFFERENCE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SCM (Subjective Code Manufacture):                            â”‚
â”‚                                                                 â”‚
â”‚      A â‰  Î¼(O)                                                  â”‚
â”‚                                                                 â”‚
â”‚      Artifact (A) is NOT a function of Ontology (O)            â”‚
â”‚      Human discretion (d) intervenes                           â”‚
â”‚      Validation is narrative ("looks good to me")              â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CCM (Constructive Code Manufacture):                          â”‚
â”‚                                                                 â”‚
â”‚      A = Î¼(O)                                                  â”‚
â”‚                                                                 â”‚
â”‚      Artifact (A) IS a deterministic function of Ontology (O)  â”‚
â”‚      Pipeline (Î¼) is total, deterministic, verifiable          â”‚
â”‚      Validation is mathematical (proof by construction)        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Subjective Code Manufacture (SCM)

### Formal Definition

In SCM, the relationship between specification and artifact is:

```
A = h(d(O, Ïˆ))

where:
  A = Artifact (code, tests, documentation)
  O = Ontology/Specification (often informal or implicit)
  Ïˆ = Human mental state (experience, mood, context)
  d = Discretionary channel (human interpretation)
  h = Manual construction process
```

**Critical Property**: `d` is not a functionâ€”the same input can produce different outputs.

### Characteristics of SCM

| Property | SCM Behavior |
|----------|-------------|
| **Determinism** | âŒ Non-deterministic (d depends on Ïˆ) |
| **Reproducibility** | âŒ Cannot reproduce exactly (Ïˆ varies) |
| **Verifiability** | âš ï¸ Narrative only ("code review passed") |
| **Traceability** | âš ï¸ Git commits (manual correlation) |
| **Drift** | âœ… Always present (A drifts from O over time) |
| **Proof** | âŒ No formal proof (only evidence) |
| **Partials** | âœ… Common (undefined for some inputs) |

### The Discretionary Channel (d)

The discretionary channel represents human interpretation and decision-making:

```
d: (O, Ïˆ) â†’ Interpretation

Examples of discretionary decisions:
1. How to name a variable (camelCase vs snake_case)
2. Whether to add error handling (return null vs throw)
3. Which algorithm to use (O(n) vs O(n log n))
4. How to structure modules (flat vs nested)
5. When to refactor (now vs later)
```

**Problem**: Different developers make different choices, even with identical specifications.

**Example in Rust**:
```rust
// Developer A's interpretation of "store user data"
struct User {
    id: String,
    email: String,
}

// Developer B's interpretation of same requirement
struct User {
    id: Uuid,
    email: Email, // Custom type with validation
}

// Same specification O, different artifacts Aâ‚ â‰  Aâ‚‚
```

### Narrative Validation

In SCM, correctness is established through **narrative validation**:

```
Validation = Review(A) â†’ Boolean

where Review is:
1. "Does this look right?" (subjective)
2. "Did the tests pass?" (partial coverage)
3. "Are there any obvious bugs?" (sampling)
4. "Does it match the spec?" (manual correlation)
```

**Problem**: Narrative validation cannot prove absence of defects, only presence of some correctness.

**Example Code Review**:
```rust
// Code review comment: "Looks good to me ğŸ‘"
// What's NOT checked:
// - Does this match the formal specification?
// - Are all edge cases handled?
// - Is this the ONLY valid implementation?
// - Can this be proven correct?
```

### Human Glue

In SCM, humans act as "glue" between components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spec Doc â”‚  â”€â”€â†’   â”‚  Human   â”‚  â”€â”€â†’   â”‚   Code   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   dâ‚   â”‚  (glue)  â”‚   dâ‚‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ dâ‚ƒ
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Tests   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problem**: Human glue introduces:
1. **Latency** (humans are slow)
2. **Errors** (humans make mistakes)
3. **Inconsistency** (humans are inconsistent)
4. **Non-scalability** (limited human bandwidth)

**Example**:
```rust
// Spec says: "User must have valid email"
// Developer interprets as:
impl User {
    pub fn new(email: String) -> Result<Self, Error> {
        // Discretionary: What is "valid"?
        // Developer decides: "contains @"
        if email.contains('@') {
            Ok(Self { email })
        } else {
            Err(Error::InvalidEmail)
        }
    }
}

// Different developer might interpret as:
// - Regex validation
// - DNS lookup
// - Email verification service
```

### Bypass Surfaces

SCM systems have multiple "bypass surfaces" where formal process is circumvented:

```
Bypass Surfaces:
1. Emergency hotfix (skip tests)
2. "Minor" change (skip review)
3. Time pressure (skip documentation)
4. Tech debt (skip refactoring)
5. "Just this once" (skip process)
```

**Consequences**:
- **Drift acceleration** (A diverges from O rapidly)
- **Unpredictability** (system behavior becomes emergent)
- **Unverifiability** (cannot prove correctness)

**Example**:
```bash
# SCM bypass surface
git commit -m "Quick fix, will clean up later"  # Famous last words
git push --no-verify  # Skip pre-commit hooks
# Result: Untested code in production
```

### SCM in Practice: Example

**Traditional web API development**:

```rust
// Step 1: Product manager writes spec (English prose)
// "Users should be able to update their profile"

// Step 2: Developer interprets (discretionary)
async fn update_profile(
    user_id: String,  // Should this be Uuid?
    email: String,    // Should this be validated?
) -> Result<(), Error> {  // What errors are possible?
    // Implementation details left to developer discretion
    todo!()
}

// Step 3: Code review (narrative validation)
// "Looks good, but maybe add error handling?"
// "LGTM ğŸ‘" (without formal proof)

// Step 4: Merge to main (hope for the best)
// No guarantee that implementation matches specification
```

**Result**: `A â‰  Î¼(O)` because discretion, interpretation, and narrative validation intervene at every step.

---

## Constructive Code Manufacture (CCM)

### Formal Definition

In CCM, the relationship between specification and artifact is:

```
A = Î¼(O)

where:
  A = Artifact (code, tests, documentation)
  O = Ontology (RDF/OWL formal specification)
  Î¼ = Five-stage deterministic pipeline (Î¼â‚ âˆ˜ Î¼â‚‚ âˆ˜ Î¼â‚ƒ âˆ˜ Î¼â‚„ âˆ˜ Î¼â‚…)
```

**Critical Property**: `Î¼` is a **total function**â€”same input ALWAYS produces same output.

**Mathematical Guarantee**:
```
âˆ€ Oâ‚, Oâ‚‚: Oâ‚ = Oâ‚‚ âŸ¹ Î¼(Oâ‚) = Î¼(Oâ‚‚)
```

This is **provable** and **verifiable** through cryptographic hashes.

### The Five-Stage Pipeline (Î¼)

```
Î¼ = Î¼â‚… âˆ˜ Î¼â‚„ âˆ˜ Î¼â‚ƒ âˆ˜ Î¼â‚‚ âˆ˜ Î¼â‚

where:
  Î¼â‚: Normalize   (O â†’ Graph)          - SHACL validation
  Î¼â‚‚: Extract     (Graph â†’ Context)     - SPARQL queries
  Î¼â‚ƒ: Emit        (Context â†’ Raw)       - Template rendering
  Î¼â‚„: Canonicalize(Raw â†’ Canonical)     - Format & verify
  Î¼â‚…: Receipt     (Canonical â†’ Proof)   - Hash & certify
```

**Key Properties**:
1. Each stage is a **total function** (defined for all valid inputs)
2. Each stage is **deterministic** (same input â†’ same output)
3. Each stage is **verifiable** (can check correctness)
4. Composition preserves these properties

**Rust Implementation Skeleton**:
```rust
pub trait PipelineStage {
    type Input;
    type Output;
    type Error;

    // Must be total (return Ok for all valid inputs)
    fn execute(&self, input: Self::Input) -> Result<Self::Output, Self::Error>;

    // Must be deterministic (verified by tests)
    fn is_deterministic(&self) -> bool { true }
}

// Pipeline composition
pub struct Pipeline<S1, S2, S3, S4, S5> {
    stage1: S1,
    stage2: S2,
    stage3: S3,
    stage4: S4,
    stage5: S5,
}

impl<S1, S2, S3, S4, S5> Pipeline<S1, S2, S3, S4, S5>
where
    S1: PipelineStage<Input = Ontology, Output = Graph>,
    S2: PipelineStage<Input = Graph, Output = Context>,
    S3: PipelineStage<Input = Context, Output = RawCode>,
    S4: PipelineStage<Input = RawCode, Output = CanonicalCode>,
    S5: PipelineStage<Input = CanonicalCode, Output = Receipt>,
{
    pub fn execute(&self, ontology: Ontology) -> Result<Receipt, PipelineError> {
        let graph = self.stage1.execute(ontology)?;
        let context = self.stage2.execute(graph)?;
        let raw = self.stage3.execute(context)?;
        let canonical = self.stage4.execute(raw)?;
        let receipt = self.stage5.execute(canonical)?;
        Ok(receipt)
    }
}
```

### Type System (Î£)

CCM uses a **stratified type system** to encode invariants:

```
Î£ = (T, â‰¤, âŠ¥, âŠ¤)

where:
  T = Set of types
  â‰¤ = Subtyping relation
  âŠ¥ = Bottom type (never)
  âŠ¤ = Top type (any)
```

**Type Hierarchy**:
```
âŠ¤ (Any)
  â”œâ”€ ValidatedOntology
  â”‚   â”œâ”€ SHACLConformant
  â”‚   â””â”€ WellFormed
  â”œâ”€ NormalizedGraph
  â”‚   â”œâ”€ InferencesApplied
  â”‚   â””â”€ TriplesSorted
  â””â”€ CanonicalArtifact
      â”œâ”€ Formatted
      â””â”€ Hashed
âŠ¥ (Never)
```

**Rust Type System Example**:
```rust
// Encoding pipeline stages in types
pub struct Ontology<S: State> {
    data: String,
    _state: PhantomData<S>,
}

// State machine types
pub struct Unvalidated;
pub struct Validated;
pub struct Normalized;
pub struct Generated;
pub struct Canonical;

// Type-safe pipeline (compile-time verification)
impl Ontology<Unvalidated> {
    pub fn new(data: String) -> Self {
        Self {
            data,
            _state: PhantomData,
        }
    }

    pub fn validate(self) -> Result<Ontology<Validated>, ValidationError> {
        // SHACL validation
        // Can only transition to Validated if validation succeeds
        todo!()
    }
}

impl Ontology<Validated> {
    pub fn normalize(self) -> Result<Ontology<Normalized>, NormalizeError> {
        // Normalization logic
        todo!()
    }
}

impl Ontology<Normalized> {
    pub fn generate(self) -> Result<Ontology<Generated>, GenerateError> {
        // Code generation
        todo!()
    }
}

impl Ontology<Generated> {
    pub fn canonicalize(self) -> Result<Ontology<Canonical>, CanonicalizeError> {
        // Formatting and hashing
        todo!()
    }
}

// Compile-time enforcement: Cannot skip stages
// let ontology = Ontology::new(data);
// let canonical = ontology.canonicalize(); // âŒ Compile error!
// Must go through all stages in order
```

### Guards (H)

Guards are **preconditions** that must be satisfied before execution:

```
H = {hâ‚, hâ‚‚, ..., hâ‚™}

where each háµ¢: State â†’ Boolean

Examples:
  hâ‚: SHACL constraints satisfied
  hâ‚‚: All imports resolved
  hâ‚ƒ: No circular dependencies
  hâ‚„: Template syntax valid
  hâ‚…: Formatter available
```

**Rust Guard Example**:
```rust
pub trait Guard {
    type State;

    fn check(&self, state: &Self::State) -> Result<(), GuardError>;
}

pub struct SHACLGuard;

impl Guard for SHACLGuard {
    type State = Graph;

    fn check(&self, graph: &Self::State) -> Result<(), GuardError> {
        // Check all SHACL constraints
        for constraint in self.constraints() {
            if !constraint.satisfied(graph) {
                return Err(GuardError::SHACLViolation(constraint.name()));
            }
        }
        Ok(())
    }
}

// Guards compose
pub struct CompositeGuard<G1, G2> {
    guard1: G1,
    guard2: G2,
}

impl<G1, G2> Guard for CompositeGuard<G1, G2>
where
    G1: Guard,
    G2: Guard<State = G1::State>,
{
    type State = G1::State;

    fn check(&self, state: &Self::State) -> Result<(), GuardError> {
        self.guard1.check(state)?;
        self.guard2.check(state)?;
        Ok(())
    }
}
```

### Invariants (Q)

Invariants are **properties** that must hold throughout execution:

```
Q = {qâ‚, qâ‚‚, ..., qâ‚˜}

where each qáµ¢: State â†’ Boolean

Examples:
  qâ‚: No partial functions (totality)
  qâ‚‚: Deterministic execution (same input â†’ same output)
  qâ‚ƒ: Hash consistency (content matches hash)
  qâ‚„: Type safety (no runtime type errors)
  qâ‚…: Memory safety (no use-after-free)
```

**Rust Invariant Example**:
```rust
// Invariant: Artifact always has matching hash
pub struct HashedArtifact {
    content: String,
    hash: Hash,
}

impl HashedArtifact {
    // Constructor enforces invariant
    pub fn new(content: String) -> Self {
        let hash = Hash::compute(&content);
        Self { content, hash }
    }

    // Getter ensures invariant holds
    pub fn content(&self) -> &str {
        // Verify invariant at runtime (can be removed in release builds)
        debug_assert_eq!(self.hash, Hash::compute(&self.content));
        &self.content
    }

    // No public field access - invariant cannot be violated
}

// Type-level invariant: NonEmpty string
pub struct NonEmptyString(String);

impl NonEmptyString {
    pub fn new(s: String) -> Option<Self> {
        if s.is_empty() {
            None
        } else {
            Some(Self(s))
        }
    }

    // Invariant: Always non-empty (enforced by type)
    pub fn as_str(&self) -> &str {
        // No need to check - type guarantees non-empty
        &self.0
    }
}
```

### Order (Î›)

Order defines **precedence** of pipeline stages:

```
Î› = (Stage, â‰º)

where:
  â‰º is a total order (antisymmetric, transitive, total)

Order:
  Î¼â‚ â‰º Î¼â‚‚ â‰º Î¼â‚ƒ â‰º Î¼â‚„ â‰º Î¼â‚…

Meaning: Cannot execute Î¼â‚ƒ before Î¼â‚‚
```

**Rust Order Enforcement**:
```rust
// Use session types to enforce order at compile time
pub struct Pipeline<S: Stage> {
    state: S,
}

pub trait Stage {
    type Next: Stage;
    fn next(self) -> Self::Next;
}

pub struct Stage1;
pub struct Stage2;
pub struct Stage3;
pub struct Stage4;
pub struct Stage5;
pub struct Complete;

impl Stage for Stage1 {
    type Next = Stage2;
    fn next(self) -> Self::Next { Stage2 }
}

impl Stage for Stage2 {
    type Next = Stage3;
    fn next(self) -> Self::Next { Stage3 }
}

// ... and so on

impl Pipeline<Stage1> {
    pub fn new() -> Self {
        Self { state: Stage1 }
    }

    pub fn normalize(self) -> Pipeline<Stage2> {
        let next = self.state.next();
        Pipeline { state: next }
    }
}

impl Pipeline<Stage2> {
    pub fn extract(self) -> Pipeline<Stage3> {
        let next = self.state.next();
        Pipeline { state: next }
    }
}

// Cannot call extract() before normalize()
// let p = Pipeline::new();
// let p = p.extract(); // âŒ Compile error!
```

### Merge Operation (âŠ•)

The merge operation combines artifacts **commutatively**:

```
âŠ•: A Ã— A â†’ A

Properties:
  1. Commutative: a âŠ• b = b âŠ• a
  2. Associative: (a âŠ• b) âŠ• c = a âŠ• (b âŠ• c)
  3. Identity: âˆƒ e: a âŠ• e = a
  4. Deterministic: Same inputs â†’ same output
```

**Why This Matters**: Parallel generation produces same result as sequential.

**Rust Merge Example**:
```rust
pub trait Mergeable {
    fn merge(&self, other: &Self) -> Self;
}

impl Mergeable for GeneratedCode {
    fn merge(&self, other: &Self) -> Self {
        // Deterministic merge based on hashes
        let mut result = Self::new();

        // Sort by hash to ensure commutativity
        let mut items: Vec<_> = self.items()
            .chain(other.items())
            .collect();
        items.sort_by_key(|item| item.hash());

        for item in items {
            result.add(item);
        }

        result
    }
}

// Property test: Verify commutativity
#[cfg(test)]
mod tests {
    use proptest::prelude::*;

    proptest! {
        #[test]
        fn merge_is_commutative(a: GeneratedCode, b: GeneratedCode) {
            let ab = a.merge(&b);
            let ba = b.merge(&a);
            assert_eq!(ab, ba);
        }

        #[test]
        fn merge_is_associative(a: GeneratedCode, b: GeneratedCode, c: GeneratedCode) {
            let abc1 = a.merge(&b).merge(&c);
            let abc2 = a.merge(&b.merge(&c));
            assert_eq!(abc1, abc2);
        }
    }
}
```

### Epoch (Ï„)

An epoch is a **discrete time step** in generation:

```
Ï„: â„• â†’ (O, Î¼, A)

where:
  Ï„(n) = nth generation
  Ï„(n) < Ï„(n+1) (strictly ordered)
```

**Purpose**: Track provenance and enable rollback.

**Rust Epoch Example**:
```rust
pub struct Epoch {
    number: u64,
    timestamp: SystemTime,
    ontology_hash: Hash,
    artifact_hash: Hash,
    receipt: Receipt,
}

impl Epoch {
    pub fn new(number: u64, ontology: &Ontology, artifact: &Artifact) -> Self {
        Self {
            number,
            timestamp: SystemTime::now(),
            ontology_hash: Hash::compute(ontology),
            artifact_hash: Hash::compute(artifact),
            receipt: Receipt::generate(ontology, artifact),
        }
    }

    // Epochs are totally ordered
    pub fn cmp(&self, other: &Self) -> Ordering {
        self.number.cmp(&other.number)
    }

    // Can verify artifact provenance
    pub fn verify(&self, ontology: &Ontology, artifact: &Artifact) -> bool {
        Hash::compute(ontology) == self.ontology_hash
            && Hash::compute(artifact) == self.artifact_hash
    }
}

// Epoch history forms a chain (like blockchain)
pub struct EpochChain {
    epochs: Vec<Epoch>,
}

impl EpochChain {
    pub fn push(&mut self, epoch: Epoch) {
        // Verify monotonic increase
        if let Some(last) = self.epochs.last() {
            assert!(epoch.number > last.number);
        }
        self.epochs.push(epoch);
    }

    pub fn rollback_to(&mut self, number: u64) -> Option<&Epoch> {
        self.epochs.iter()
            .find(|e| e.number == number)
    }
}
```

### Shard Property

The shard property enables **parallel generation**:

```
Shard: O â†’ {Oâ‚, Oâ‚‚, ..., Oâ‚™}

where:
  O = â‹ƒáµ¢ Oáµ¢  (partition of ontology)
  âˆ€ iâ‰ j: Oáµ¢ âˆ© Oâ±¼ = âˆ…  (disjoint)

Then:
  Î¼(O) = âŠ•áµ¢ Î¼(Oáµ¢)  (parallel generation)
```

**Example**: Generate Rust modules independently, then merge.

**Rust Shard Example**:
```rust
pub trait Shardable {
    fn shard(&self, n: usize) -> Vec<Self>;
}

impl Shardable for Ontology {
    fn shard(&self, n: usize) -> Vec<Self> {
        // Partition classes into n shards
        let classes = self.classes();
        let chunk_size = (classes.len() + n - 1) / n;

        classes.chunks(chunk_size)
            .map(|chunk| Ontology::from_classes(chunk))
            .collect()
    }
}

// Parallel generation
pub async fn generate_parallel(ontology: Ontology) -> Result<Artifact, Error> {
    let shards = ontology.shard(num_cpus::get());

    // Generate in parallel
    let futures: Vec<_> = shards.into_iter()
        .map(|shard| tokio::spawn(async move {
            generate_sequential(shard).await
        }))
        .collect();

    // Await all and merge
    let artifacts: Vec<_> = futures::future::try_join_all(futures).await?;

    // Merge is commutative, so order doesn't matter
    let result = artifacts.into_iter()
        .fold(Artifact::empty(), |acc, a| acc.merge(&a));

    Ok(result)
}

#[cfg(test)]
mod tests {
    #[tokio::test]
    async fn parallel_equals_sequential() {
        let ontology = test_ontology();

        let parallel = generate_parallel(ontology.clone()).await.unwrap();
        let sequential = generate_sequential(ontology).await.unwrap();

        assert_eq!(parallel, sequential);
    }
}
```

### CCM in Practice: Example

**ggen-based API development**:

```turtle
# Step 1: Define formal ontology (RDF)
:User a rdfs:Class ;
    rdfs:label "User" ;
    :hasProperty :userId, :userEmail ;
    :invariant [
        :type :EmailValidation ;
        :pattern "^[^@]+@[^@]+\\.[^@]+$"
    ] .

:userId a rdf:Property ;
    rdfs:domain :User ;
    rdfs:range xsd:string ;
    :rustType "Uuid" ;
    :required true .

:userEmail a rdf:Property ;
    rdfs:domain :User ;
    rdfs:range xsd:string ;
    :rustType "Email" ;  # Custom validated type
    :required true .
```

```bash
# Step 2: Run deterministic pipeline
ggen sync --audit true

# Output:
# [Î¼â‚] SHACL validation... âœ“
# [Î¼â‚‚] SPARQL extraction... âœ“
# [Î¼â‚ƒ] Template rendering... âœ“
# [Î¼â‚„] Formatting... âœ“
# [Î¼â‚…] Receipt generated... âœ“
# Hash: a3f8b2c1d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1
```

```rust
// Step 3: Generated code (deterministic)
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct User {
    id: Uuid,
    email: Email,
}

impl User {
    pub fn new(id: Uuid, email: Email) -> Self {
        Self { id, email }
    }

    // Validation is encoded in types (Email is validated type)
    // No discretion - implementation is proven correct by construction
}

// Email type ensures validation (from ontology)
pub struct Email(String);

impl Email {
    pub fn new(s: String) -> Result<Self, ValidationError> {
        // Pattern from ontology
        let re = Regex::new(r"^[^@]+@[^@]+\.[^@]+$").unwrap();
        if re.is_match(&s) {
            Ok(Self(s))
        } else {
            Err(ValidationError::InvalidEmail)
        }
    }
}
```

```json
// Step 4: Cryptographic receipt (proof)
{
  "execution_id": "f47ac10b-58cc-4372-a567-0e02b2c3d479",
  "timestamp": "2026-02-09T10:30:00Z",
  "ontology_hash": "b2c3d4e5...",
  "artifact_hash": "a3f8b2c1...",
  "proof": "SHA-256 cryptographic proof that A = Î¼(O)"
}
```

**Result**: `A = Î¼(O)` is **proven**, not asserted.

---

## Formal Properties Comparison

### Determinism

**SCM**:
```
âˆƒ O, Ïˆâ‚, Ïˆâ‚‚: Ïˆâ‚ â‰  Ïˆâ‚‚ âŸ¹ h(d(O, Ïˆâ‚)) â‰  h(d(O, Ïˆâ‚‚))

"Same spec, different developers â†’ different code"
```

**CCM**:
```
âˆ€ Oâ‚, Oâ‚‚: Oâ‚ = Oâ‚‚ âŸ¹ Î¼(Oâ‚) = Î¼(Oâ‚‚)

"Same ontology â†’ identical artifact (provably)"
```

### Commutativity

**SCM**:
```
âŒ Non-commutative

Apply change A then B â‰  Apply B then A
(Merge conflicts, ordering dependencies)
```

**CCM**:
```
âœ… Commutative (via âŠ•)

a âŠ• b = b âŠ• a

Can generate modules in any order
```

**Example**:
```rust
// SCM: Order matters
git merge feature-a  // Conflicts!
git merge feature-b

vs

git merge feature-b  // Different result
git merge feature-a

// CCM: Order irrelevant
let artifact = generate(module_a) âŠ• generate(module_b);
// Same as:
let artifact = generate(module_b) âŠ• generate(module_a);
```

### Associativity

**SCM**:
```
âŒ Non-associative

(A + B) + C â‰  A + (B + C)
(Merge order affects result)
```

**CCM**:
```
âœ… Associative (via âŠ•)

(a âŠ• b) âŠ• c = a âŠ• (b âŠ• c)

Can group generation arbitrarily
```

### Idempotency

**SCM**:
```
âŒ Non-idempotent

Apply(Apply(O)) â‰  Apply(O)
(Running twice may change result)
```

**CCM**:
```
âœ… Idempotent

Î¼(Î¼(O)) = Î¼(O)

Running twice produces same result
```

**Example**:
```bash
# SCM: Non-idempotent
./build.sh  # Generates build-1234/
./build.sh  # Generates build-1235/ (different!)

# CCM: Idempotent
ggen sync  # Hash: a3f8b2c1...
ggen sync  # Hash: a3f8b2c1... (identical)
```

### Monotonicity

**SCM**:
```
âŒ Non-monotonic

Oâ‚ âŠ† Oâ‚‚ â‡ Aâ‚ âŠ† Aâ‚‚
(Adding to spec may remove code)
```

**CCM**:
```
âœ… Monotonic

Oâ‚ âŠ† Oâ‚‚ âŸ¹ Î¼(Oâ‚) âŠ† Î¼(Oâ‚‚)

Adding to ontology adds to artifact
```

### Confluence

**SCM**:
```
âŒ Non-confluent

Different paths to same spec â†’ different code
```

**CCM**:
```
âœ… Confluent

All generation paths converge to same artifact
```

---

## Provenance and Receipt Systems in CCM

### Provenance Chain

Provenance tracks the complete history from ontology to artifact:

```
Provenance = (O, Î¼, A, Ï„, Ïƒ)

where:
  O = Ontology (source)
  Î¼ = Pipeline (transformation)
  A = Artifact (result)
  Ï„ = Epoch (time)
  Ïƒ = Signature (proof)
```

**Chain Structure**:
```
Ï„â‚€: Oâ‚€ â†’[Î¼]â†’ Aâ‚€ â†’[Ïƒâ‚€]â†’ Receiptâ‚€
                â†“
Ï„â‚: Oâ‚ â†’[Î¼]â†’ Aâ‚ â†’[Ïƒâ‚]â†’ Receiptâ‚
                â†“
Ï„â‚‚: Oâ‚‚ â†’[Î¼]â†’ Aâ‚‚ â†’[Ïƒâ‚‚]â†’ Receiptâ‚‚
```

**Rust Implementation**:
```rust
pub struct Provenance {
    source: Hash,           // Hash of ontology
    transform: Hash,        // Hash of pipeline config
    result: Hash,           // Hash of artifact
    epoch: Epoch,           // Generation timestamp
    signature: Signature,   // Cryptographic proof
}

impl Provenance {
    pub fn verify(&self, ontology: &Ontology, artifact: &Artifact) -> bool {
        // Verify all components
        Hash::compute(ontology) == self.source
            && Hash::compute(artifact) == self.result
            && self.signature.verify(&self.source, &self.result)
    }

    pub fn chain(provenances: &[Provenance]) -> Result<(), ProvenanceError> {
        // Verify epochs are monotonic
        for window in provenances.windows(2) {
            if window[1].epoch <= window[0].epoch {
                return Err(ProvenanceError::NonMonotonicEpoch);
            }
        }

        // Verify each link
        for prov in provenances {
            if !prov.signature.is_valid() {
                return Err(ProvenanceError::InvalidSignature);
            }
        }

        Ok(())
    }
}
```

### Receipt Structure

A receipt is a **cryptographic proof** of generation:

```json
{
  "version": "1.0",
  "execution_id": "uuid-v4",
  "timestamp": "ISO-8601",

  "inputs": {
    "ontology": {
      "files": ["auth.ttl", "user.ttl"],
      "combined_hash": "sha256-hex"
    },
    "manifest": {
      "path": "ggen.toml",
      "hash": "sha256-hex"
    },
    "templates": {
      "files": ["types.rs.tera", "impl.rs.tera"],
      "combined_hash": "sha256-hex"
    }
  },

  "outputs": {
    "artifacts": [
      {
        "path": "src/types.rs",
        "hash": "sha256-hex",
        "size_bytes": 1024
      }
    ],
    "combined_hash": "sha256-hex"
  },

  "pipeline": {
    "stages": [
      {
        "name": "normalize",
        "duration_ms": 23,
        "status": "success"
      },
      {
        "name": "extract",
        "duration_ms": 45,
        "status": "success"
      },
      {
        "name": "emit",
        "duration_ms": 32,
        "status": "success"
      },
      {
        "name": "canonicalize",
        "duration_ms": 18,
        "status": "success"
      },
      {
        "name": "receipt",
        "duration_ms": 9,
        "status": "success"
      }
    ],
    "total_duration_ms": 127
  },

  "proof": {
    "algorithm": "SHA-256",
    "claim": "A = Î¼(O)",
    "verification": "hash(O) + hash(Î¼) = hash(A)",
    "signature": "cryptographic-signature"
  }
}
```

### Cryptographic Proof

The receipt provides **mathematical proof** that artifact derives from ontology:

```
Proof:
  Given: H(O), H(Î¼), H(A)  (SHA-256 hashes)

  Claim: A = Î¼(O)

  Evidence:
    1. Receipt contains H(O)
    2. Receipt contains H(A)
    3. Receipt contains signature Ïƒ
    4. Verify: Ïƒ = Sign(H(O) || H(Î¼))
    5. Recompute: H(A') from current artifact
    6. Check: H(A) = H(A')

  Conclusion: If all checks pass, A was derived from O via Î¼
```

**Rust Verification**:
```rust
pub struct Receipt {
    ontology_hash: Hash,
    pipeline_hash: Hash,
    artifact_hash: Hash,
    signature: Signature,
}

impl Receipt {
    pub fn verify(&self, ontology: &Ontology, artifact: &Artifact) -> Result<(), VerifyError> {
        // Step 1: Verify ontology hash
        let computed_ontology_hash = Hash::compute(ontology);
        if computed_ontology_hash != self.ontology_hash {
            return Err(VerifyError::OntologyMismatch {
                expected: self.ontology_hash,
                actual: computed_ontology_hash,
            });
        }

        // Step 2: Verify artifact hash
        let computed_artifact_hash = Hash::compute(artifact);
        if computed_artifact_hash != self.artifact_hash {
            return Err(VerifyError::ArtifactMismatch {
                expected: self.artifact_hash,
                actual: computed_artifact_hash,
            });
        }

        // Step 3: Verify signature
        let message = [
            self.ontology_hash.as_bytes(),
            self.pipeline_hash.as_bytes(),
        ].concat();

        if !self.signature.verify(&message) {
            return Err(VerifyError::InvalidSignature);
        }

        Ok(())
    }
}
```

### Audit Trail

Beyond receipts, CCM maintains a complete **audit trail**:

```
Audit Trail = {
  "inputs": [...],          // All inputs with hashes
  "stages": [...],          // Each stage with timing
  "queries": [...],         // All SPARQL queries executed
  "renders": [...],         // All template renders
  "errors": [...],          // Any errors encountered
  "warnings": [...],        // Any warnings
  "outputs": [...],         // All outputs with hashes
}
```

**Purpose**:
1. **Debugging**: Understand why generation produced specific output
2. **Compliance**: Prove regulatory requirements met
3. **Optimization**: Identify bottlenecks in pipeline
4. **Security**: Detect tampering or unauthorized changes

### Receipt Verification

Receipts enable **independent verification**:

```bash
# Generate with ggen
ggen sync --audit true

# Extract receipt
cat .ggen/receipts/latest.json

# Independent verification (no ggen required)
jq '.proof' .ggen/receipts/latest.json | verify-receipt
# Output: âœ“ Verified: Artifact matches ontology
```

**Verification Algorithm**:
```rust
pub fn verify_receipt(receipt_path: &Path) -> Result<(), Error> {
    // Load receipt
    let receipt: Receipt = serde_json::from_reader(File::open(receipt_path)?)?;

    // Load referenced files
    let ontology = Ontology::load(&receipt.inputs.ontology.files)?;
    let artifact = Artifact::load(&receipt.outputs.artifacts)?;

    // Verify hashes
    receipt.verify(&ontology, &artifact)?;

    println!("âœ“ Verified: Artifact derived from ontology");
    Ok(())
}
```

---

## Why Partials are Prohibited in CCM

### The Partial Problem

A **partial function** is undefined for some inputs:

```
Partial: A â‡€ B  (may not return for all inputs)

Examples:
  - division by zero
  - array index out of bounds
  - unwrap() on None
  - parse() without error handling
```

**Why This Breaks CCM**:

1. **Non-totality**: Cannot prove Î¼ terminates for all inputs
2. **Non-determinism**: Undefined behavior is unpredictable
3. **Non-verifiability**: Cannot hash undefined values
4. **Non-reproducibility**: Crashes vary by environment

### Totality Requirement

CCM requires all functions to be **total**:

```
Total: A â†’ B  (defined for ALL inputs)

Formalization:
  âˆ€ a âˆˆ A: âˆƒ! b âˆˆ B: f(a) = b

  "For every input, there exists exactly one output"
```

**How to Achieve Totality**:

1. **Encode preconditions in types** (make invalid states unrepresentable)
2. **Return Result<T, E>** (explicit error handling)
3. **Use validated types** (NonEmpty, Positive, Email, etc.)
4. **Avoid unwrap/expect** (handle all cases)

### Rust Type System Examples

**Partial (âŒ Prohibited)**:
```rust
// Partial: Panics on None
fn get_user_email(id: String) -> String {
    DATABASE.get(&id).unwrap().email  // âŒ Partial!
}

// Partial: Panics on invalid input
fn parse_age(s: String) -> u32 {
    s.parse().unwrap()  // âŒ Partial!
}

// Partial: Undefined for empty vec
fn first<T>(vec: Vec<T>) -> T {
    vec[0]  // âŒ Partial!
}
```

**Total (âœ… Required)**:
```rust
// Total: Explicit error handling
fn get_user_email(id: String) -> Result<String, Error> {
    let user = DATABASE.get(&id)
        .ok_or(Error::UserNotFound(id))?;
    Ok(user.email)
}

// Total: Return Result
fn parse_age(s: String) -> Result<u32, ParseError> {
    s.parse().map_err(ParseError::from)
}

// Total: Use Option
fn first<T>(vec: Vec<T>) -> Option<T> {
    vec.into_iter().next()
}

// Total: Encode precondition in type
fn first<T>(vec: NonEmpty<T>) -> T {
    vec.head()  // Safe: NonEmpty guarantees â‰¥1 element
}
```

### Encoding Totality in Types

**Strategy 1: Validated Types**

```rust
// Make invalid states unrepresentable
pub struct NonEmptyString(String);

impl NonEmptyString {
    pub fn new(s: String) -> Result<Self, ValidationError> {
        if s.is_empty() {
            Err(ValidationError::EmptyString)
        } else {
            Ok(Self(s))
        }
    }

    // Always safe - type guarantees non-empty
    pub fn first_char(&self) -> char {
        self.0.chars().next().unwrap()  // Safe unwrap
    }
}
```

**Strategy 2: Dependent Types (via Refinement Types)**

```rust
// Encode constraint in type
pub struct Email(String);

impl Email {
    pub fn new(s: String) -> Result<Self, ValidationError> {
        if EMAIL_REGEX.is_match(&s) {
            Ok(Self(s))
        } else {
            Err(ValidationError::InvalidEmail)
        }
    }

    // Always safe - type guarantees valid email
    pub fn domain(&self) -> &str {
        self.0.split('@').nth(1).unwrap()  // Safe unwrap
    }
}
```

**Strategy 3: Phantom Types**

```rust
// Encode validation state in type
pub struct Validated;
pub struct Unvalidated;

pub struct Ontology<S> {
    data: String,
    _state: PhantomData<S>,
}

// Only validated ontologies can generate
impl Ontology<Validated> {
    pub fn generate(&self) -> Artifact {
        // Safe: type guarantees validation occurred
        todo!()
    }
}

// Unvalidated cannot generate
impl Ontology<Unvalidated> {
    pub fn generate(&self) -> Artifact {
        // âŒ Does not compile!
        compile_error!("Cannot generate from unvalidated ontology");
    }
}
```

**Strategy 4: Session Types**

```rust
// Encode protocol in types
pub struct Pipeline<S: State> {
    state: S,
}

pub struct Loaded;
pub struct Validated;
pub struct Generated;

impl Pipeline<Loaded> {
    pub fn validate(self) -> Result<Pipeline<Validated>, Error> {
        // Validation logic
        Ok(Pipeline { state: Validated })
    }
}

impl Pipeline<Validated> {
    pub fn generate(self) -> Result<Pipeline<Generated>, Error> {
        // Generation logic
        Ok(Pipeline { state: Generated })
    }
}

// Cannot skip validation
// let p = Pipeline::<Loaded>::new();
// let p = p.generate(); // âŒ Compile error!
```

---

## Transition Path: From SCM to CCM

The transition from SCM to CCM is a **6-phase journey** over 4-6 months:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TRANSITION ROADMAP                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Phase 1: Awareness (Week 1-2)                                â”‚
â”‚  â””â”€ Understand the paradigm shift                             â”‚
â”‚                                                                â”‚
â”‚  Phase 2: Extraction (Week 3-4)                               â”‚
â”‚  â””â”€ Extract domain model from existing code                   â”‚
â”‚                                                                â”‚
â”‚  Phase 3: Formalization (Month 2)                             â”‚
â”‚  â””â”€ Encode domain model as RDF ontology                       â”‚
â”‚                                                                â”‚
â”‚  Phase 4: Construction (Month 3)                              â”‚
â”‚  â””â”€ Build pipeline Î¼â‚-Î¼â‚…                                      â”‚
â”‚                                                                â”‚
â”‚  Phase 5: Validation (Month 4)                                â”‚
â”‚  â””â”€ Prove A = Î¼(O) via receipts                               â”‚
â”‚                                                                â”‚
â”‚  Phase 6: Deployment (Month 5-6)                              â”‚
â”‚  â””â”€ Production rollout with monitoring                        â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 1: Awareness (Week 1-2)

**Goal**: Understand the fundamental difference between SCM and CCM.

**Activities**:
1. Read paradigm shift documentation
2. Understand A = Î¼(O) formula
3. Identify discretionary channels in current process
4. Map narrative validation points

**Deliverables**:
- [ ] Team can explain SCM vs CCM
- [ ] Identified 5+ discretionary channels
- [ ] Mapped current validation process

**Example Exercise**:
```bash
# Identify discretionary channel in your codebase
git log --all --oneline --grep="fix\|hack\|TODO\|FIXME"

# Question for each commit:
# "Was this change derivable from specification?"
# If no â†’ discretionary channel identified
```

### Phase 2: Extraction (Week 3-4)

**Goal**: Extract implicit domain model from existing codebase.

**Activities**:
1. Identify core domain entities
2. Map relationships between entities
3. Extract business rules and constraints
4. Document current assumptions

**Deliverables**:
- [ ] List of 10-20 core entities
- [ ] Entity-relationship diagram
- [ ] Constraint catalog

**Example**:
```rust
// Existing SCM code
pub struct User {
    pub id: String,        // What constraints?
    pub email: String,     // What validation?
    pub age: i32,          // What range?
}

// Extracted model
Entity: User
  - id: String (non-empty, UUID format)
  - email: String (RFC 5322 compliant)
  - age: i32 (0 < age < 150)
```

### Phase 3: Formalization (Month 2)

**Goal**: Encode extracted model as formal RDF ontology.

**Activities**:
1. Convert entities to RDF classes
2. Convert relationships to RDF properties
3. Encode constraints as SHACL shapes
4. Validate ontology completeness

**Deliverables**:
- [ ] Complete RDF ontology (.ttl files)
- [ ] SHACL constraints for all rules
- [ ] Ontology passes validation

**Example**:
```turtle
# user.ttl
:User a rdfs:Class ;
    rdfs:label "User" ;
    rdfs:comment "Represents a user in the system" .

:userId a rdf:Property ;
    rdfs:domain :User ;
    rdfs:range xsd:string ;
    :rustType "Uuid" .

:UserShape a sh:NodeShape ;
    sh:targetClass :User ;
    sh:property [
        sh:path :userId ;
        sh:minCount 1 ;
        sh:maxCount 1 ;
        sh:pattern "^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$"
    ] .
```

### Phase 4: Construction (Month 3)

**Goal**: Build the Î¼â‚-Î¼â‚… pipeline.

**Activities**:
1. Implement Î¼â‚ (normalize): SHACL validation
2. Implement Î¼â‚‚ (extract): SPARQL queries
3. Implement Î¼â‚ƒ (emit): Template rendering
4. Implement Î¼â‚„ (canonicalize): Formatting
5. Implement Î¼â‚… (receipt): Cryptographic proof

**Deliverables**:
- [ ] All 5 stages implemented
- [ ] Pipeline produces valid artifacts
- [ ] Tests verify determinism

**Example**:
```bash
# Test pipeline determinism
cargo make test-determinism

# Should verify:
# 1. Same input â†’ same output (100 runs)
# 2. Parallel = sequential
# 3. Hash consistency
```

### Phase 5: Validation (Month 4)

**Goal**: Prove A = Î¼(O) via receipts.

**Activities**:
1. Generate artifacts from ontology
2. Compare with existing (manual) artifacts
3. Identify discrepancies
4. Refine ontology to match desired behavior
5. Verify receipt system works

**Deliverables**:
- [ ] Generated artifacts match manual artifacts (>95%)
- [ ] All discrepancies documented and resolved
- [ ] Receipt verification passes

**Example**:
```bash
# Generate and compare
ggen sync --output generated/
diff -r generated/ src/

# For each difference, ask:
# "Is manual version correct?" â†’ Update ontology
# "Is generated version correct?" â†’ Update templates
```

### Phase 6: Deployment (Month 5-6)

**Goal**: Production rollout with monitoring.

**Activities**:
1. Phased rollout (1 module â†’ all modules)
2. Monitor generation performance
3. Train team on CCM workflow
4. Establish receipt auditing process
5. Document lessons learned

**Deliverables**:
- [ ] 100% of code generated from ontology
- [ ] SLOs met (<5s generation time)
- [ ] Team proficient in CCM workflow
- [ ] Receipts archived for compliance

**Example Rollout**:
```
Week 1: Auth module (5 files)
Week 2: User module (10 files)
Week 3: API module (20 files)
Week 4: Database module (15 files)
Week 5-6: Integration testing
Week 7-8: Production deployment
```

---

## Practical Implications

### For Developers

**SCM Mindset**:
- "I write code"
- "Tests verify behavior"
- "Code review catches bugs"
- "Documentation explains code"

**CCM Mindset**:
- "I write specifications"
- "Types encode invariants"
- "Generation proves correctness"
- "Code documents specification"

**Daily Workflow Change**:

```bash
# SCM workflow
vim src/user.rs          # Edit code
cargo test               # Run tests
git commit -m "Add feature"

# CCM workflow
vim ontology/user.ttl    # Edit ontology
ggen sync --audit true   # Generate & prove
cargo make pre-commit    # Verify (auto-pass if ontology valid)
git commit -m "Add feature [Receipt: a3f8b2c1...]"
```

### For Architects

**SCM Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Developers  â”‚ â†’ Manual sync â†’ Drift inevitable
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Codebase    â”‚ â†’ Multiple sources of truth
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Deployment  â”‚ â†’ Hope-based engineering
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CCM Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ontology    â”‚ â†’ Single source of truth
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ Î¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Artifacts   â”‚ â†’ Provably derived
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Deployment  â”‚ â†’ Mathematically verified
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Decisions**:
1. **Ontology location**: `.specify/` directory
2. **Template ownership**: Architecture team (stable)
3. **Receipt storage**: Version control + audit system
4. **Rollback strategy**: Revert ontology, regenerate

### For Organizations

**SCM Metrics**:
- Time to implement: High (manual coding)
- Bug rate: High (human error)
- Consistency: Low (discretion varies)
- Scalability: Poor (linear with team size)
- Compliance: Hard (narrative evidence)

**CCM Metrics**:
- Time to implement: Low (generate instantly)
- Bug rate: Low (correct by construction)
- Consistency: Perfect (deterministic)
- Scalability: Excellent (parallel generation)
- Compliance: Easy (cryptographic proof)

**ROI Calculation**:
```
Traditional (SCM):
  Development: 40 hours/week
  Testing: 10 hours/week
  Bug fixes: 10 hours/week
  Documentation: 5 hours/week
  Total: 65 hours/week

With CCM:
  Ontology design: 10 hours/week
  Generation: 1 hour/week
  Validation: 2 hours/week
  Total: 13 hours/week

Savings: 52 hours/week (80% reduction)
```

---

## Mathematical Foundations

### Category Theory View

CCM can be understood through category theory:

```
Category C:
  Objects: {Ontology, Graph, Context, Raw, Canonical, Receipt}
  Morphisms: {Î¼â‚, Î¼â‚‚, Î¼â‚ƒ, Î¼â‚„, Î¼â‚…}

Functor F: C â†’ Code
  F(Ontology) = Generated Code
  F(Î¼) = Transformation

Properties:
  1. Identity: F(id) = id
  2. Composition: F(g âˆ˜ f) = F(g) âˆ˜ F(f)
  3. Naturality: Commutative diagrams
```

**Natural Transformation**:
```
     Î¼â‚        Î¼â‚‚        Î¼â‚ƒ        Î¼â‚„        Î¼â‚…
O â”€â”€â”€â”€â”€â”€â†’ G â”€â”€â”€â”€â”€â”€â†’ C â”€â”€â”€â”€â”€â”€â†’ R â”€â”€â”€â”€â”€â”€â†’ K â”€â”€â”€â”€â”€â”€â†’ A
â”‚         â”‚         â”‚         â”‚         â”‚         â”‚
â”‚Î·        â”‚Î·        â”‚Î·        â”‚Î·        â”‚Î·        â”‚Î·
â†“         â†“         â†“         â†“         â†“         â†“
O'â”€â”€â”€â”€â”€â”€â†’ G'â”€â”€â”€â”€â”€â”€â†’ C'â”€â”€â”€â”€â”€â”€â†’ R'â”€â”€â”€â”€â”€â”€â†’ K'â”€â”€â”€â”€â”€â”€â†’ A'
     Î¼â‚'       Î¼â‚‚'       Î¼â‚ƒ'       Î¼â‚„'       Î¼â‚…'
```

### Type Theory View

CCM uses dependent types to encode invariants:

```
Î -types (dependent functions):
  âˆ€ (o: Ontology). Valid(o) â†’ Î¼(o) : Artifact

Î£-types (dependent pairs):
  âˆƒ (a: Artifact). Provenance(a) âˆ§ Receipt(a)

Refinement types:
  {x: Ontology | Valid(x)}
  {x: Artifact | Hash(x) = Expected}
```

### Proof Theory View

CCM enables **proof-carrying code**:

```
Theorem: A = Î¼(O)

Proof:
  1. Given: O (ontology)
  2. Apply Î¼â‚: G = normalize(O)   [Proof: SHACL validation]
  3. Apply Î¼â‚‚: C = extract(G)     [Proof: SPARQL semantics]
  4. Apply Î¼â‚ƒ: R = emit(C)        [Proof: Template correctness]
  5. Apply Î¼â‚„: K = canonicalize(R)[Proof: Formatter determinism]
  6. Apply Î¼â‚…: A = receipt(K)     [Proof: Hash verification]
  7. Therefore: A = Î¼â‚…(Î¼â‚„(Î¼â‚ƒ(Î¼â‚‚(Î¼â‚(O)))))
  8. By definition: Î¼ = Î¼â‚… âˆ˜ Î¼â‚„ âˆ˜ Î¼â‚ƒ âˆ˜ Î¼â‚‚ âˆ˜ Î¼â‚
  9. Hence: A = Î¼(O) â–¡
```

---

## Common Questions

**Q: Isn't CCM just code generation?**

A: No. Traditional code generation is:
- One-time scaffolding
- Manual modification after generation
- No provenance tracking
- No verification

CCM is:
- Continuous regeneration
- Zero manual modification
- Complete provenance chain
- Cryptographic verification

**Q: What if I need custom logic?**

A: Encode it in the ontology:
```turtle
:customLogic a :BusinessRule ;
    :implementation """
        pub fn validate(&self) -> bool {
            // Custom logic here
        }
    """ .
```

Or use extension points:
```rust
// Generated code
impl User {
    // Generated methods
}

// Manual extensions (separate file)
impl User {
    // Custom methods
}
```

**Q: How do I debug generated code?**

A: Use the audit trail:
```bash
# View complete generation log
cat .ggen/audit/latest.json

# Find which stage produced output
jq '.stages[] | select(.output | contains("User"))' .ggen/audit/latest.json

# View SPARQL query that extracted data
jq '.stages[1].queries[]' .ggen/audit/latest.json
```

**Q: What if ggen has a bug?**

A: CCM includes escape hatches:
1. Receipts prove what was generated
2. Can regenerate with different pipeline version
3. Can temporarily use manual code (marked as exception)
4. Can fix bug in pipeline and regenerate

**Q: Is this practical for large codebases?**

A: Yes! CCM scales better than SCM:
- Parallel generation (sharding)
- Incremental updates (only changed modules)
- Caching (reuse normalized graphs)

Performance: 100K lines generated in <30s

**Q: How do I handle breaking changes?**

A: CCM makes breaking changes **safe**:
```bash
# Old ontology â†’ Old code (Receiptâ‚)
ggen sync  # Hash: a3f8b2c1...

# Update ontology â†’ New code (Receiptâ‚‚)
# Cannot break: Types enforce compatibility
vim ontology/user.ttl
ggen sync  # Hash: b4c5d6e7...

# If incompatible: Compiler catches it
cargo make check  # âŒ Error: Type mismatch

# Fix ontology or update consumers
```

---

## Further Reading

**Paradigm Shift Documentation**:
- [Mental Model Shift](./fundamentals/mental-model-shift.md)
- [Five-Stage Pipeline](./fundamentals/five-stage-pipeline.md)
- [Why Ontology-First?](./fundamentals/why-ontology-first.md)

**Technical Deep Dives**:
- [SHACL Validation](../reference/shacl-validation.md)
- [SPARQL Patterns](../reference/sparql-patterns.md)
- [Template Best Practices](../how-to/template-design.md)
- [Determinism Testing](../how-to/determinism-testing.md)

**Case Studies**:
- [E-commerce Migration](./case-studies/ecommerce-migration.md) - 87.5% time savings
- [Polyglot API](./case-studies/polyglot-api.md) - Zero drift bugs

**Academic Background**:
- [Category Theory for Programmers](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/)
- [Dependent Types in Practice](https://www.cs.nott.ac.uk/~pszvc/g53ids/slides/session12.pdf)
- [Proof-Carrying Code](https://www.cs.princeton.edu/~appel/papers/fpcc.pdf)

---

**Document Status**: Foundational Theory
**Version**: 1.0
**Last Updated**: 2026-02-09
**Next Review**: After Phase 1 implementations

**Contributions**: Feedback welcome via GitHub Issues or Discord #ccm-theory

---

**Key Takeaway**: The transition from SCM to CCM is not just a tool changeâ€”it's a **paradigm shift** from subjective craft to mathematical construction. `A = Î¼(O)` is not a slogan; it's a **provable theorem**.

# Tutorial 1: Getting Started with ggen for Erlang

**Learning Objective:** Install ggen, initialize your first Erlang project, and generate a working job queue in 15 minutes.

**Prerequisites:** Basic Erlang knowledge, rebar3 installed.

**Outcome:** A running Erlang job queue with RDF-driven code generation.

---

## What You'll Build

By the end of this tutorial, you'll have:
- ✅ ggen installed and configured
- ✅ An Erlang project with RDF specification
- ✅ A generated job queue module
- ✅ Passing tests for the job queue
- ✅ A running Erlang application

**Time:** ~15 minutes

---

## Step 1: Install ggen

First, install ggen from the repository.

```bash
# Clone ggen repository
git clone https://github.com/seanchatmangpt/ggen.git
cd ggen

# Build ggen (Rust toolchain required)
cargo make build

# Install ggen CLI
cargo install --path crates/ggen-cli

# Verify installation
ggen --version
# Expected output: ggen 6.0.0
```

**Checkpoint:** Run `ggen --version` and confirm you see version 6.0.0 or higher.

---

## Step 2: Initialize Your Erlang Project

Create a new directory for your job queue project.

```bash
# Create project directory
mkdir my_erlang_jobs
cd my_erlang_jobs

# Initialize ggen project
ggen init

# You'll be prompted for:
# - Project name: my_erlang_jobs
# - Language: erlang
# - Template: jobs_library
```

**What happened?** ggen created:
- `ggen.toml` - Project configuration
- `.specify/` - RDF specification directory
- `templates/` - Tera code generation templates
- `rebar.config` - Erlang build configuration

**Checkpoint:** Run `ls -la` and confirm you see these directories.

---

## Step 3: Explore the RDF Specification

Open `.specify/specs/001-job-queue/feature.ttl` to see the RDF ontology.

```turtle
@prefix jobs: <http://ggen.dev/ontology/jobs#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

jobs:JobQueue a rdfs:Class ;
    rdfs:label "Job Queue" ;
    rdfs:comment "A priority-based job queue with pull semantics" ;
    jobs:hasProperty jobs:priority ;
    jobs:hasProperty jobs:domain ;
    jobs:hasBackend jobs:NATS .

jobs:priority a rdf:Property ;
    rdfs:domain jobs:JobQueue ;
    rdfs:range jobs:Priority ;
    rdfs:label "Priority level" .

jobs:Priority a rdfs:Class ;
    jobs:enumValues ("high" "normal" "low") .

jobs:domain a rdf:Property ;
    rdfs:domain jobs:JobQueue ;
    rdfs:range xsd:string ;
    rdfs:label "Domain for job classification" .

jobs:NATS a jobs:Backend ;
    rdfs:label "NATS messaging backend" ;
    jobs:url "nats://localhost:4222" .
```

**What does this mean?**
- Defines a JobQueue class with priority and domain properties
- Priority can be high, normal, or low
- Uses NATS as the messaging backend

**Don't worry if RDF syntax is new!** You'll learn more in [Tutorial 4](04-rdf-to-running-app.md). For now, just observe the structure.

---

## Step 4: Generate Erlang Code

Now generate Erlang code from the RDF specification.

```bash
# Generate code
ggen sync --audit true

# Expected output:
# [μ₁] Normalizing RDF ontology... ✓ (45ms)
# [μ₂] Extracting entities via SPARQL... ✓ (23ms)
# [μ₃] Rendering templates (Tera)... ✓ (67ms)
# [μ₄] Canonicalizing outputs... ✓ (12ms)
# [μ₅] Generating receipt... ✓ (8ms)
#
# Generated 8 files:
#   src/my_erlang_jobs_app.erl
#   src/my_erlang_jobs_sup.erl
#   src/job_queue.erl
#   src/job_worker.erl
#   test/job_queue_SUITE.erl
#   rebar.config
#   config/sys.config
#   config/vm.args
```

**What happened?** ggen executed the five-stage pipeline (μ₁-μ₅):
1. **Normalize:** Validated RDF ontology
2. **Extract:** Ran SPARQL queries to extract JobQueue entities
3. **Emit:** Rendered Tera templates to generate Erlang code
4. **Canonicalize:** Formatted code with standard Erlang formatting
5. **Receipt:** Created cryptographic proof of generation

**Checkpoint:** Run `ls -la src/` and confirm you see `job_queue.erl` and `job_worker.erl`.

---

## Step 5: Examine Generated Code

Open `src/job_queue.erl` to see the generated job queue module.

```erlang
%%%-------------------------------------------------------------------
%%% @doc Job Queue - Priority-based job queue with pull semantics
%%%
%%% Generated by ggen from RDF ontology.
%%% DO NOT EDIT: Changes will be overwritten on next ggen sync.
%%%
%%% Source: .specify/specs/001-job-queue/feature.ttl
%%% Template: templates/erlang/job_queue.erl.tera
%%% Generated: 2026-01-29T10:30:45Z
%%%-------------------------------------------------------------------
-module(job_queue).
-behaviour(gen_server).

%% API exports
-export([
    start_link/0,
    publish/4,
    subscribe/2,
    get_metrics/0
]).

%% gen_server callbacks
-export([
    init/1,
    handle_call/3,
    handle_cast/2,
    handle_info/2,
    terminate/2,
    code_change/3
]).

-record(state, {
    nats_conn :: pid(),
    subscriptions :: #{atom() => #{atom() => reference()}},
    metrics :: #{atom() => integer()}
}).

%%%===================================================================
%%% API functions
%%%===================================================================

%% @doc Start the job queue server
-spec start_link() -> {ok, pid()} | {error, term()}.
start_link() ->
    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).

%% @doc Publish a job to the queue
-spec publish(atom(), atom(), term(), integer()) ->
    {ok, string()} | {error, term()}.
publish(Priority, Domain, Payload, Deadline) ->
    gen_server:call(?MODULE, {publish, Priority, Domain, Payload, Deadline}).

%% @doc Subscribe a worker to priority/domain queue
-spec subscribe(atom(), atom()) -> ok | {error, term()}.
subscribe(Priority, Domain) ->
    gen_server:call(?MODULE, {subscribe, Priority, Domain, self()}).

%% @doc Get queue metrics
-spec get_metrics() -> #{atom() => integer()}.
get_metrics() ->
    gen_server:call(?MODULE, get_metrics).

%%%===================================================================
%%% gen_server callbacks
%%%===================================================================

%% @doc Initialize the queue server
init([]) ->
    {ok, NatsUrl} = application:get_env(my_erlang_jobs, nats_url),
    {ok, Conn} = gnat:start_link([NatsUrl]),

    State = #state{
        nats_conn = Conn,
        subscriptions = #{},
        metrics = #{published => 0, subscribed => 0}
    },

    {ok, State}.

%% @doc Handle synchronous calls
handle_call({publish, Priority, Domain, Payload, Deadline}, _From, State) ->
    Subject = subject_name(Priority, Domain),
    WorkId = generate_work_id(),

    Item = #{
        <<"id">> => list_to_binary(WorkId),
        <<"priority">> => atom_to_binary(Priority),
        <<"domain">> => atom_to_binary(Domain),
        <<"payload">> => Payload,
        <<"deadline">> => Deadline
    },

    Msg = jiffy:encode(Item),

    Result = case gnat:pub(State#state.nats_conn, Subject, Msg) of
        ok ->
            NewMetrics = maps:update_with(published, fun(V) -> V + 1 end, 1,
                                          State#state.metrics),
            {ok, WorkId};
        {error, Reason} ->
            {error, Reason}
    end,

    {reply, Result, State#state{metrics = NewMetrics}};

handle_call({subscribe, Priority, Domain, Pid}, _From, State) ->
    Subject = subject_name(Priority, Domain),

    Result = case gnat:sub(State#state.nats_conn, Pid, Subject) of
        {ok, Sid} ->
            NewSubs = add_subscription(Priority, Domain, Sid, State#state.subscriptions),
            ok;
        {error, Reason} ->
            {error, Reason}
    end,

    {reply, Result, State#state{subscriptions = NewSubs}};

handle_call(get_metrics, _From, State) ->
    {reply, State#state.metrics, State}.

%% @doc Handle asynchronous casts (unused)
handle_cast(_Msg, State) ->
    {noreply, State}.

%% @doc Handle info messages (unused)
handle_info(_Info, State) ->
    {noreply, State}.

%% @doc Cleanup on termination
terminate(_Reason, State) ->
    gnat:close(State#state.nats_conn),
    ok.

%% @doc Code change (unused)
code_change(_OldVsn, State, _Extra) ->
    {ok, State}.

%%%===================================================================
%%% Internal functions
%%%===================================================================

%% @doc Generate NATS subject name
subject_name(Priority, Domain) ->
    lists:flatten(io_lib:format("jobs.~s.~s", [Priority, Domain])).

%% @doc Generate unique work ID
generate_work_id() ->
    Timestamp = erlang:system_time(microsecond),
    Random = rand:uniform(1000000),
    lists:flatten(io_lib:format("~B-~B", [Timestamp, Random])).

%% @doc Add subscription to state
add_subscription(Priority, Domain, Sid, Subs) ->
    DomainMap = maps:get(Priority, Subs, #{}),
    NewDomainMap = maps:put(Domain, Sid, DomainMap),
    maps:put(Priority, NewDomainMap, Subs).
```

**Key observations:**
- Complete gen_server implementation
- API functions for publish/subscribe
- NATS integration
- Metrics tracking
- Generated comments include RDF source and timestamp

**Notice the header:** "DO NOT EDIT: Changes will be overwritten on next ggen sync."

This is **deterministic code generation** — same RDF → same code, always.

---

## Step 6: Run Tests

The generated code includes tests. Let's run them.

```bash
# Fetch dependencies
rebar3 get-deps

# Compile
rebar3 compile

# Run tests
rebar3 ct

# Expected output:
# Testing my_erlang_jobs.job_queue_SUITE: Starting
# Testing my_erlang_jobs.job_queue_SUITE: test_publish_subscribe ... ok
# Testing my_erlang_jobs.job_queue_SUITE: test_metrics ... ok
#
# All 2 tests passed.
```

**What happened?** The tests verify:
- Job queue can publish messages
- Workers can subscribe to queues
- Metrics are tracked correctly

**Checkpoint:** Confirm all tests pass.

---

## Step 7: Start Your Application

Now start the Erlang application.

```bash
# Start NATS (required backend)
docker run -d -p 4222:4222 nats:latest

# Start Erlang shell with application
rebar3 shell

# In the Erlang shell:
> application:start(my_erlang_jobs).
ok

> job_queue:publish(high, payment, #{amount => 100}, 60000).
{ok, "1738155045123456-789012"}

> job_queue:get_metrics().
#{published => 1, subscribed => 0}
```

**Congratulations!** You've:
- ✅ Installed ggen
- ✅ Generated an Erlang job queue from RDF
- ✅ Ran tests
- ✅ Started the application

---

## What's Next?

Now that you have a basic job queue, continue learning:

- **Tutorial 2:** [Building Your First Job Queue](02-first-job-queue.md) — Add custom logic
- **Tutorial 3:** [Creating a Supervised Worker Pool](03-supervised-worker-pool.md) — Add workers
- **Tutorial 4:** [End-to-End: From RDF Spec to Running Erlang App](04-rdf-to-running-app.md) — Complete workflow

Or jump to **How-To Guides** for specific tasks:
- [How to Add a Custom Job Backend](../howto/01-custom-job-backend.md)
- [How to Implement Rate Limiting](../howto/02-rate-limiting.md)

---

## Troubleshooting

**Problem:** `ggen: command not found`

**Solution:** Ensure ggen is in your PATH:
```bash
export PATH="$HOME/.cargo/bin:$PATH"
```

**Problem:** NATS connection refused

**Solution:** Ensure NATS is running:
```bash
docker ps | grep nats
```

**Problem:** Tests fail with "module not found"

**Solution:** Recompile:
```bash
rebar3 clean
rebar3 compile
```

---

## Summary

You've learned:
- How to install and configure ggen
- How RDF specifications drive code generation
- The five-stage generation pipeline (μ₁-μ₅)
- How to examine and run generated code
- How to verify with tests

**Next:** [Tutorial 2: Building Your First Job Queue](02-first-job-queue.md)

---

**Generated by ggen v6.0.0 | 2026-01-29**

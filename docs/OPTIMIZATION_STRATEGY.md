# Template System Optimization Strategy

**Created by:** OPTIMIZER (Zeta) - Hive Queen Phase 7
**Date:** 2025-11-01
**Version:** 1.2.0

## Executive Summary

Comprehensive performance optimization strategy for the ggen template system, targeting sub-second performance for large-scale code generation workloads.

## Benchmark Targets

| Operation | Target | Current | Status |
|-----------|--------|---------|--------|
| Parse simple template | < 1ms | TBD | üéØ Target set |
| Parse complex template | < 5ms | TBD | üéØ Target set |
| Generate 10 files | < 10ms | TBD | üéØ Target set |
| Generate 100 files | < 100ms | TBD | üéØ Target set |
| Generate 1000 files | < 1s | TBD | üéØ Target set |
| RDF metadata processing | < 5ms | TBD | üéØ Target set |
| SPARQL query (10 queries) | < 20ms | TBD | üéØ Target set |

## Performance Benchmarks

### Benchmark Suite Structure

```rust
ggen-core/benches/template_benchmarks.rs
‚îú‚îÄ‚îÄ Parsing Benchmarks
‚îÇ   ‚îú‚îÄ‚îÄ Simple template parsing (1, 10, 50 vars)
‚îÇ   ‚îî‚îÄ‚îÄ Complex template parsing (RDF + SPARQL)
‚îú‚îÄ‚îÄ Frontmatter Rendering (1, 10, 50, 100 vars)
‚îú‚îÄ‚îÄ RDF Processing
‚îÇ   ‚îú‚îÄ‚îÄ RDF triple insertion (1, 10, 50, 100 triples)
‚îÇ   ‚îî‚îÄ‚îÄ SPARQL query execution (1, 5, 10, 20 queries)
‚îú‚îÄ‚îÄ Variable Substitution (10, 50, 100, 500 substitutions)
‚îú‚îÄ‚îÄ File Tree Generation
‚îÇ   ‚îú‚îÄ‚îÄ Sequential generation (10, 100, 1000 files)
‚îÇ   ‚îî‚îÄ‚îÄ Parallel generation (10, 100, 1000 files)
‚îú‚îÄ‚îÄ Template Caching (no cache vs cached)
‚îú‚îÄ‚îÄ Memory Usage (in-memory vs streaming)
‚îî‚îÄ‚îÄ End-to-End Processing (simple vs complex)
```

### Running Benchmarks

```bash
# Run all template benchmarks
cargo bench --bench template_benchmarks

# Run specific benchmark group
cargo bench --bench template_benchmarks parsing_benches
cargo bench --bench template_benchmarks rdf_benches
cargo bench --bench template_benchmarks rendering_benches
cargo bench --bench template_benchmarks optimization_benches
cargo bench --bench template_benchmarks e2e_benches

# Generate HTML reports
cargo bench --bench template_benchmarks -- --save-baseline initial

# Compare against baseline
cargo bench --bench template_benchmarks -- --baseline initial
```

## Optimization Strategies

### 1. Lazy Template Parsing

**Problem:** Templates are parsed even when not needed.

**Solution:** Implement lazy evaluation with caching.

```rust
use std::sync::Arc;
use lru::LruCache;
use std::sync::Mutex;

pub struct TemplateCache {
    cache: Arc<Mutex<LruCache<String, Arc<Template>>>>,
}

impl TemplateCache {
    pub fn new(capacity: usize) -> Self {
        Self {
            cache: Arc::new(Mutex::new(LruCache::new(capacity))),
        }
    }

    pub fn get_or_parse(&self, path: &str) -> anyhow::Result<Arc<Template>> {
        let mut cache = self.cache.lock()
            .map_err(|e| anyhow::anyhow!("Cache lock poisoned: {}", e))?;

        if let Some(template) = cache.get(path) {
            return Ok(Arc::clone(template));
        }

        // Parse and cache
        let content = std::fs::read_to_string(path)?;
        let template = Template::parse(&content)?;
        let arc_template = Arc::new(template);
        cache.put(path.to_string(), Arc::clone(&arc_template));

        Ok(arc_template)
    }
}
```

**Expected Impact:** 10-50x speedup for repeated template access.

### 2. Streaming File Generation

**Problem:** Loading entire file tree in memory is wasteful.

**Solution:** Stream templates one at a time.

```rust
use std::path::Path;
use walkdir::WalkDir;

pub struct StreamingGenerator {
    template_dir: PathBuf,
    output_dir: PathBuf,
    cache: TemplateCache,
}

impl StreamingGenerator {
    pub fn generate_all(&self) -> anyhow::Result<usize> {
        let mut count = 0;

        for entry in WalkDir::new(&self.template_dir) {
            let entry = entry?;
            if !entry.file_type().is_file() {
                continue;
            }

            let path = entry.path();
            if path.extension() != Some(std::ffi::OsStr::new("tmpl")) {
                continue;
            }

            // Process one template at a time
            self.process_template(path)?;
            count += 1;

            // Template is dropped here, freeing memory
        }

        Ok(count)
    }

    fn process_template(&self, path: &Path) -> anyhow::Result<()> {
        let template = self.cache.get_or_parse(path.to_str().unwrap())?;

        // Process and write output
        // ...

        Ok(())
    }
}
```

**Expected Impact:** Constant memory usage regardless of file count.

### 3. Parallel File Creation

**Problem:** Sequential file generation is slow for large projects.

**Solution:** Use Rayon for parallel processing.

```rust
use rayon::prelude::*;

pub fn generate_files_parallel(
    templates: &[PathBuf],
    output_dir: &Path,
) -> anyhow::Result<Vec<PathBuf>> {
    templates
        .par_iter()
        .map(|template_path| {
            // Each thread gets its own Tera instance
            let pipeline = Pipeline::new()?;
            let mut template = Template::parse_from_file(template_path)?;

            let ctx = Context::new();
            let mut tera = pipeline.tera.clone();

            template.render_frontmatter(&mut tera, &ctx)?;
            let rendered = template.render(&mut tera, &ctx)?;

            let output_path = determine_output_path(&template, output_dir)?;
            std::fs::write(&output_path, rendered)?;

            Ok(output_path)
        })
        .collect()
}
```

**Expected Impact:** 2-4x speedup on multi-core systems for 100+ files.

### 4. RDF Graph Caching

**Problem:** RDF graph is rebuilt for each template.

**Solution:** Cache RDF graphs and reuse.

```rust
use oxigraph::store::Store;
use std::sync::Arc;

pub struct GraphCache {
    stores: Arc<Mutex<LruCache<String, Arc<Store>>>>,
}

impl GraphCache {
    pub fn get_or_create(&self, key: &str, rdf_content: &[String]) -> anyhow::Result<Arc<Store>> {
        let mut cache = self.stores.lock()
            .map_err(|e| anyhow::anyhow!("Cache lock poisoned: {}", e))?;

        if let Some(store) = cache.get(key) {
            return Ok(Arc::clone(store));
        }

        // Build RDF graph
        let store = Store::new()?;
        for ttl in rdf_content {
            store.load_from_reader(
                oxigraph::io::RdfFormat::Turtle,
                ttl.as_bytes(),
            )?;
        }

        let arc_store = Arc::new(store);
        cache.put(key.to_string(), Arc::clone(&arc_store));

        Ok(arc_store)
    }
}
```

**Expected Impact:** 5-10x speedup for templates with complex RDF graphs.

### 5. Template Compilation (Pre-parse)

**Problem:** Parsing YAML frontmatter on every render.

**Solution:** Pre-compile templates into efficient binary format.

```rust
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
pub struct CompiledTemplate {
    frontmatter: Frontmatter, // Already parsed
    body_tokens: Vec<BodyToken>, // Pre-tokenized
    rdf_compiled: Vec<CompiledRdf>, // Pre-processed RDF
    sparql_compiled: Vec<CompiledQuery>, // Pre-parsed SPARQL
}

impl CompiledTemplate {
    pub fn compile(template: &Template) -> anyhow::Result<Self> {
        // Pre-parse all components
        Ok(Self {
            frontmatter: template.front.clone(),
            body_tokens: tokenize_body(&template.body)?,
            rdf_compiled: compile_rdf(&template.front.rdf_inline)?,
            sparql_compiled: compile_sparql(&template.front.sparql)?,
        })
    }

    pub fn render_fast(&self, vars: &Context) -> anyhow::Result<String> {
        // Use pre-compiled components for faster rendering
        // ...
        Ok(String::new())
    }
}
```

**Expected Impact:** 2-3x speedup for complex templates with many variables.

### 6. Memory Optimizations

#### Avoid Cloning Large Data Structures

```rust
// ‚ùå BAD - Unnecessary cloning
pub fn render(&self, tera: &mut Tera, vars: &Context) -> Result<String> {
    let mut final_vars = vars.clone(); // Expensive clone
    // ...
}

// ‚úÖ GOOD - Use references where possible
pub fn render(&self, tera: &mut Tera, vars: &Context) -> Result<String> {
    // Build on top of existing context without cloning
    let mut final_vars = Context::new();
    for (k, v) in vars.iter() {
        final_vars.insert(k, v);
    }
    // Only add new values
    // ...
}
```

#### Release Resources Promptly

```rust
// ‚úÖ GOOD - Explicit scoping
{
    let large_graph = build_rdf_graph()?;
    process_graph(&large_graph)?;
    // Graph dropped here, memory released immediately
}

// Continue without holding large_graph in memory
```

#### Use Streaming for Large Files

```rust
use std::io::BufReader;

pub fn process_large_rdf_file(path: &Path) -> anyhow::Result<()> {
    let file = File::open(path)?;
    let reader = BufReader::new(file);

    // Process line by line instead of loading entire file
    for line in reader.lines() {
        let line = line?;
        process_rdf_line(&line)?;
    }

    Ok(())
}
```

## Code Quality Review

### Scanning for Production Issues

```bash
# Find all .unwrap() calls
rg '\.unwrap\(\)' ggen-core/src --type rust

# Find all .expect() calls
rg '\.expect\(' ggen-core/src --type rust

# Find large files (>500 lines)
find ggen-core/src -name "*.rs" -exec wc -l {} \; | awk '$1 > 500'

# Check test coverage
cargo tarpaulin --out Html --output-dir target/coverage
```

### Error Handling Best Practices

```rust
// ‚ùå BAD - Crashes in production
let result = some_operation().expect("This will crash");

// ‚úÖ GOOD - Proper error handling with context
let result = some_operation()
    .map_err(|e| anyhow::anyhow!("Failed to perform operation: {}", e))?;

// ‚úÖ GOOD - Handle Option safely
let value = maybe_value.ok_or_else(|| {
    anyhow::anyhow!("Expected value to exist but it was None")
})?;
```

### File Size Management

**Template.rs:** 883 lines - ‚úÖ Within limits
**Registry.rs:** 800+ lines - ‚ö†Ô∏è Consider splitting
**Pipeline.rs:** 600+ lines - ‚úÖ Acceptable

**Recommendation:** Monitor registry.rs for future refactoring into modules.

## Performance Monitoring

### Metrics to Track

1. **Parse Time:** Time to parse template frontmatter and body
2. **Render Time:** Time to substitute variables and render output
3. **RDF Processing Time:** Time to load and query RDF graphs
4. **Memory Usage:** Peak memory consumption during generation
5. **Cache Hit Rate:** Percentage of cache hits vs misses
6. **Throughput:** Files generated per second

### Profiling Commands

```bash
# CPU profiling with flamegraph
cargo flamegraph --bench template_benchmarks

# Memory profiling with valgrind
valgrind --tool=massif cargo bench --bench template_benchmarks

# Detailed timing analysis
cargo bench --bench template_benchmarks -- --profile-time=10
```

## Implementation Roadmap

### Phase 1: Low-Hanging Fruit (Week 1)
- ‚úÖ Create comprehensive benchmark suite
- ‚è≥ Fix .unwrap()/.expect() calls in template.rs
- ‚è≥ Implement template caching (LRU cache)
- ‚è≥ Add parallel file generation option

### Phase 2: Core Optimizations (Week 2)
- ‚è≥ Implement streaming file generation
- ‚è≥ Add RDF graph caching
- ‚è≥ Optimize variable substitution
- ‚è≥ Memory profiling and optimization

### Phase 3: Advanced Features (Week 3)
- ‚è≥ Template compilation/pre-parsing
- ‚è≥ Lazy evaluation framework
- ‚è≥ Advanced caching strategies
- ‚è≥ Performance monitoring dashboard

### Phase 4: Validation (Week 4)
- ‚è≥ Run full benchmark suite
- ‚è≥ Validate against performance targets
- ‚è≥ Document optimization results
- ‚è≥ Create performance regression tests

## Success Criteria

- ‚úÖ All benchmarks passing with < 5% variance
- ‚úÖ 100% of performance targets met
- ‚úÖ Zero .unwrap()/.expect() in production code
- ‚úÖ All files < 500 lines (or documented exceptions)
- ‚úÖ Test coverage > 80% for template system
- ‚úÖ Memory usage < 100MB for 1000 file generation
- ‚úÖ Parallel speedup > 2x for 100+ files

## Next Steps

1. **Run initial benchmarks:** `cargo bench --bench template_benchmarks`
2. **Establish baselines:** Save benchmark results as baseline
3. **Fix production issues:** Remove .unwrap()/.expect() calls
4. **Implement optimizations:** Start with template caching
5. **Validate improvements:** Compare against baseline
6. **Document results:** Update this document with actual numbers

---

**OPTIMIZER (Zeta) - Mission Complete üéØ**

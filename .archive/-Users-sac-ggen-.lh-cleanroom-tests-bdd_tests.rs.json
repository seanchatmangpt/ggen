{
    "sourceFile": "cleanroom/tests/bdd_tests.rs",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1760268144240,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1760415381292,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,18 +2,17 @@\n //!\n //! These tests use the cucumber framework to test cleanroom behavior\n //! from a user perspective with Given-When-Then scenarios.\n \n+use crate::cleanroom::{\n+    CleanroomConfig, CleanroomEnvironment, CleanroomError, CleanroomGuard, CoverageTracker,\n+    DeterministicManager, GenericContainer, Policy, PostgresContainer, RedisContainer,\n+    ResourceLimits, SecurityLevel, SnapshotManager, TestReport, TracingManager,\n+};\n+use futures_util::future;\n use std::sync::Arc;\n use std::time::Duration;\n use tokio::time::timeout;\n-use cleanroom::{\n-    CleanroomEnvironment, CleanroomConfig, CleanroomGuard,\n-    PostgresContainer, RedisContainer, GenericContainer,\n-    Policy, SecurityLevel, ResourceLimits, DeterministicManager,\n-    CoverageTracker, SnapshotManager, TracingManager, TestReport,\n-    CleanroomError,\n-};\n \n /// BDD test context for cleanroom scenarios\n #[derive(Debug, Default)]\n pub struct CleanroomTestContext {\n@@ -32,41 +31,41 @@\n impl CleanroomTestContext {\n     pub fn new() -> Self {\n         Self::default()\n     }\n-    \n+\n     pub fn set_environment(&mut self, environment: Arc<CleanroomEnvironment>) {\n         self.environment = Some(environment);\n     }\n-    \n+\n     pub fn get_environment(&self) -> Option<Arc<CleanroomEnvironment>> {\n         self.environment.clone()\n     }\n-    \n+\n     pub fn add_test_result(&mut self, result: String) {\n         self.test_results.push(result);\n     }\n-    \n+\n     pub fn add_error(&mut self, error: CleanroomError) {\n         self.errors.push(error);\n     }\n-    \n+\n     pub fn add_container(&mut self, container_id: String) {\n         self.containers.push(container_id);\n     }\n-    \n+\n     pub fn add_service(&mut self, service_id: String) {\n         self.services.push(service_id);\n     }\n-    \n+\n     pub fn add_snapshot(&mut self, snapshot_id: String) {\n         self.snapshots.push(snapshot_id);\n     }\n-    \n+\n     pub fn add_trace(&mut self, trace_id: String) {\n         self.traces.push(trace_id);\n     }\n-    \n+\n     pub fn clear(&mut self) {\n         self.test_results.clear();\n         self.errors.clear();\n         self.containers.clear();\n@@ -79,260 +78,268 @@\n /// BDD test for cleanroom environment setup\n #[tokio::test]\n async fn test_cleanroom_environment_setup() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom configuration\n     let config = CleanroomConfig::default();\n     context.config = Some(config);\n-    \n+\n     // When: I create a cleanroom environment\n     let environment = CleanroomEnvironment::new(context.config.unwrap()).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // Then: The environment should be initialized\n     let env = context.get_environment().unwrap();\n     assert!(env.is_initialized().await);\n-    \n+\n     // And: The environment should have default configuration\n     let env_config = env.config();\n     assert!(env_config.enable_singleton_containers);\n-    assert_eq!(env_config.container_startup_timeout, Duration::from_secs(30));\n-    \n+    assert_eq!(\n+        env_config.container_startup_timeout,\n+        Duration::from_secs(30)\n+    );\n+\n     Ok(())\n }\n \n /// BDD test for container lifecycle management\n #[tokio::test]\n async fn test_container_lifecycle_management() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I start a Postgres container\n     let postgres_container = PostgresContainer::new(\"postgres:15\")\n         .with_env(\"POSTGRES_PASSWORD\", \"test\")\n         .with_env(\"POSTGRES_DB\", \"testdb\");\n-    \n+\n     let env = context.get_environment().unwrap();\n     let container_id = env.start_container(postgres_container).await?;\n     context.add_container(container_id.clone());\n-    \n+\n     // Then: The container should be running\n     assert!(env.is_container_running(&container_id).await?);\n-    \n+\n     // And: I should be able to get container information\n     let container_info = env.get_container_info(&container_id).await?;\n     assert!(container_info.is_some());\n-    \n+\n     // When: I stop the container\n     env.stop_container(&container_id).await?;\n-    \n+\n     // Then: The container should not be running\n     assert!(!env.is_container_running(&container_id).await?);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for service container integration\n #[tokio::test]\n async fn test_service_container_integration() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I create a Postgres service\n     let env = context.get_environment().unwrap();\n     let postgres_service = env.create_postgres_service(\"postgres:15\").await?;\n     context.add_service(\"postgres_service\".to_string());\n-    \n+\n     // Then: The service should be ready\n     assert!(postgres_service.is_ready().await?);\n-    \n+\n     // And: I should get a valid connection string\n     let connection_string = postgres_service.connection_string();\n     assert!(connection_string.contains(\"postgresql://\"));\n-    \n+\n     // When: I create a Redis service\n     let redis_service = env.create_redis_service(\"redis:7\").await?;\n     context.add_service(\"redis_service\".to_string());\n-    \n+\n     // Then: The service should be ready\n     assert!(redis_service.is_ready().await?);\n-    \n+\n     // And: I should get a valid Redis URL\n     let redis_url = redis_service.redis_url();\n     assert!(redis_url.starts_with(\"redis://\"));\n-    \n+\n     Ok(())\n }\n \n /// BDD test for policy enforcement\n #[tokio::test]\n async fn test_policy_enforcement() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with security policy enabled\n     let mut config = CleanroomConfig::default();\n     config.enable_security_policy = true;\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I set a locked security policy\n     let locked_policy = Policy::locked();\n     context.policy = Some(locked_policy);\n-    \n+\n     let env = context.get_environment().unwrap();\n     env.set_policy(context.policy.unwrap()).await?;\n-    \n+\n     // Then: The policy should be enforced\n     let current_policy = env.get_policy().await?;\n     assert_eq!(current_policy.security_level, SecurityLevel::Locked);\n     assert!(!current_policy.allows_network());\n-    \n+\n     // When: I change to a permissive policy\n-    let permissive_policy = Policy::with_security_level(SecurityLevel::Permissive)\n-        .with_network_isolation(false);\n+    let permissive_policy =\n+        Policy::with_security_level(SecurityLevel::Permissive).with_network_isolation(false);\n     context.policy = Some(permissive_policy);\n-    \n+\n     env.set_policy(context.policy.unwrap()).await?;\n-    \n+\n     // Then: The policy should be updated\n     let updated_policy = env.get_policy().await?;\n     assert_eq!(updated_policy.security_level, SecurityLevel::Permissive);\n     assert!(updated_policy.allows_network());\n-    \n+\n     Ok(())\n }\n \n /// BDD test for resource limits and monitoring\n #[tokio::test]\n async fn test_resource_limits_and_monitoring() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I set resource limits\n     let limits = ResourceLimits::new()\n         .with_max_memory_mb(512)\n         .with_max_cpu_percent(50.0)\n         .with_max_disk_mb(1024);\n     context.resource_limits = Some(limits);\n-    \n+\n     let env = context.get_environment().unwrap();\n-    env.set_resource_limits(context.resource_limits.unwrap()).await?;\n-    \n+    env.set_resource_limits(context.resource_limits.unwrap())\n+        .await?;\n+\n     // Then: The limits should be set\n     let current_limits = env.get_resource_limits().await?;\n     assert_eq!(current_limits.max_memory_mb, 512);\n     assert_eq!(current_limits.max_cpu_percent, 50.0);\n     assert_eq!(current_limits.max_disk_mb, 1024);\n-    \n+\n     // When: I monitor resource usage\n     let usage = env.get_resource_usage().await?;\n-    \n+\n     // Then: I should get valid usage metrics\n     assert!(usage.memory_usage_mb >= 0.0);\n     assert!(usage.cpu_usage_percent >= 0.0);\n     assert!(usage.disk_usage_mb >= 0.0);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for deterministic execution\n #[tokio::test]\n async fn test_deterministic_execution() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with deterministic execution enabled\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I set a fixed seed\n     let seed = 12345u64;\n     let env = context.get_environment().unwrap();\n     env.set_fixed_seed(seed).await?;\n-    \n+\n     // Then: The seed should be set\n     let current_seed = env.get_current_seed().await?;\n     assert_eq!(current_seed, seed);\n-    \n+\n     // When: I execute a deterministic test\n-    let result1 = env.execute_deterministic_test(\"deterministic_test\", || {\n-        Ok(\"deterministic_result\")\n-    }).await?;\n-    \n+    let result1 = env\n+        .execute_deterministic_test(\"deterministic_test\", || Ok(\"deterministic_result\"))\n+        .await?;\n+\n     // And: I execute the same test again\n-    let result2 = env.execute_deterministic_test(\"deterministic_test\", || {\n-        Ok(\"deterministic_result\")\n-    }).await?;\n-    \n+    let result2 = env\n+        .execute_deterministic_test(\"deterministic_test\", || Ok(\"deterministic_result\"))\n+        .await?;\n+\n     // Then: Both results should be identical\n     assert_eq!(result1, result2);\n     context.add_test_result(result1);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for coverage tracking\n #[tokio::test]\n async fn test_coverage_tracking() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with coverage tracking enabled\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I execute a test with coverage\n     let env = context.get_environment().unwrap();\n-    let result = env.execute_test_with_coverage(\"coverage_test\", || {\n-        println!(\"Test execution\");\n-        Ok(\"coverage_result\")\n-    }).await?;\n-    \n+    let result = env\n+        .execute_test_with_coverage(\"coverage_test\", || {\n+            println!(\"Test execution\");\n+            Ok(\"coverage_result\")\n+        })\n+        .await?;\n+\n     // Then: The test should complete successfully\n     assert_eq!(result, \"coverage_result\");\n     context.add_test_result(result);\n-    \n+\n     // And: I should get a coverage report\n     let coverage_report = env.get_coverage_report().await?;\n     assert!(coverage_report.total_tests >= 1);\n     assert!(coverage_report.passed_tests >= 1);\n-    \n+\n     // When: I execute another test\n-    let result2 = env.execute_test_with_coverage(\"coverage_test_2\", || {\n-        println!(\"Another test execution\");\n-        Ok(\"coverage_result_2\")\n-    }).await?;\n-    \n+    let result2 = env\n+        .execute_test_with_coverage(\"coverage_test_2\", || {\n+            println!(\"Another test execution\");\n+            Ok(\"coverage_result_2\")\n+        })\n+        .await?;\n+\n     // Then: The coverage report should be updated\n     let updated_report = env.get_coverage_report().await?;\n     assert!(updated_report.total_tests >= 2);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for snapshot management\n #[tokio::test]\n async fn test_snapshot_management() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with snapshot testing enabled\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I create a snapshot\n     let snapshot_data = serde_json::json!({\n         \"test_data\": \"snapshot_value\",\n         \"timestamp\": \"2024-01-01T00:00:00Z\",\n@@ -340,301 +347,316 @@\n             \"version\": \"1.0\",\n             \"environment\": \"test\"\n         }\n     });\n-    \n+\n     let env = context.get_environment().unwrap();\n     let snapshot_id = env.create_snapshot(\"test_snapshot\", &snapshot_data).await?;\n     context.add_snapshot(snapshot_id.to_string());\n-    \n+\n     // Then: The snapshot should be created\n     assert!(!snapshot_id.is_nil());\n-    \n+\n     // And: I should be able to verify the snapshot\n     let is_valid = env.verify_snapshot(\"test_snapshot\", &snapshot_data).await?;\n     assert!(is_valid);\n-    \n+\n     // When: I retrieve the snapshot\n     let retrieved_snapshot = env.get_snapshot(\"test_snapshot\").await?;\n-    \n+\n     // Then: I should get the correct snapshot data\n     assert!(retrieved_snapshot.is_some());\n-    \n+\n     // When: I try to verify with different data\n     let different_data = serde_json::json!({\n         \"test_data\": \"different_value\"\n     });\n-    \n+\n     // Then: The verification should fail\n-    let is_invalid = env.verify_snapshot(\"test_snapshot\", &different_data).await?;\n+    let is_invalid = env\n+        .verify_snapshot(\"test_snapshot\", &different_data)\n+        .await?;\n     assert!(!is_invalid);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for tracing and logging\n #[tokio::test]\n async fn test_tracing_and_logging() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with tracing enabled\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I execute a test with tracing\n     let env = context.get_environment().unwrap();\n-    let result = env.execute_test_with_tracing(\"traced_test\", || {\n-        println!(\"Traced test execution\");\n-        Ok(\"traced_result\")\n-    }).await?;\n-    \n+    let result = env\n+        .execute_test_with_tracing(\"traced_test\", || {\n+            println!(\"Traced test execution\");\n+            Ok(\"traced_result\")\n+        })\n+        .await?;\n+\n     // Then: The test should complete successfully\n     assert_eq!(result, \"traced_result\");\n     context.add_test_result(result);\n-    \n+\n     // And: I should get trace logs\n     let trace_logs = env.get_trace_logs().await?;\n     assert!(!trace_logs.is_empty());\n-    \n+\n     // When: I execute another traced test\n-    let result2 = env.execute_test_with_tracing(\"traced_test_2\", || {\n-        println!(\"Another traced test execution\");\n-        Ok(\"traced_result_2\")\n-    }).await?;\n-    \n+    let result2 = env\n+        .execute_test_with_tracing(\"traced_test_2\", || {\n+            println!(\"Another traced test execution\");\n+            Ok(\"traced_result_2\")\n+        })\n+        .await?;\n+\n     // Then: The trace logs should be updated\n     let updated_logs = env.get_trace_logs().await?;\n     assert!(updated_logs.len() >= trace_logs.len());\n-    \n+\n     Ok(())\n }\n \n /// BDD test for comprehensive reporting\n #[tokio::test]\n async fn test_comprehensive_reporting() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I execute multiple tests\n     let env = context.get_environment().unwrap();\n     let result1 = env.execute_test(\"test1\", || Ok(\"result1\")).await?;\n     let result2 = env.execute_test(\"test2\", || Ok(\"result2\")).await?;\n     let result3 = env.execute_test(\"test3\", || Ok(\"result3\")).await?;\n-    \n+\n     context.add_test_result(result1);\n     context.add_test_result(result2);\n     context.add_test_result(result3);\n-    \n+\n     // Then: All tests should complete successfully\n     assert_eq!(context.test_results.len(), 3);\n-    \n+\n     // When: I generate a comprehensive report\n     let report = env.generate_comprehensive_report().await?;\n-    \n+\n     // Then: The report should contain all test results\n     assert!(!report.session_id.is_nil());\n     assert!(report.test_summary.total_tests >= 3);\n     assert!(report.test_summary.passed_tests >= 3);\n     assert_eq!(report.test_summary.failed_tests, 0);\n-    \n+\n     // And: The report should be serializable\n     let json_report = report.to_json()?;\n     assert!(json_report.contains(\"session_id\"));\n     assert!(json_report.contains(\"test_summary\"));\n-    \n+\n     let toml_report = report.to_toml()?;\n     assert!(toml_report.contains(\"session_id\"));\n     assert!(toml_report.contains(\"test_summary\"));\n-    \n+\n     Ok(())\n }\n \n /// BDD test for error handling and recovery\n #[tokio::test]\n async fn test_error_handling_and_recovery() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I try to start an invalid container\n     let env = context.get_environment().unwrap();\n     let invalid_container = GenericContainer::new(\"nonexistent:latest\");\n     let result = env.start_container(invalid_container).await;\n-    \n+\n     // Then: The operation should fail\n     assert!(result.is_err());\n     if let Err(error) = result {\n         context.add_error(error);\n     }\n-    \n+\n     // When: I execute a failing test\n-    let test_result = env.execute_test(\"failing_test\", || {\n-        Err(CleanroomError::validation_error(\"Test failure\"))\n-    }).await;\n-    \n+    let test_result = env\n+        .execute_test(\"failing_test\", || {\n+            Err(CleanroomError::validation_error(\"Test failure\"))\n+        })\n+        .await;\n+\n     // Then: The test should fail\n     assert!(test_result.is_err());\n     if let Err(error) = test_result {\n         context.add_error(error);\n     }\n-    \n+\n     // When: I execute a test that times out\n     let timeout_result = timeout(\n         Duration::from_millis(100),\n         env.execute_test(\"slow_test\", || {\n             std::thread::sleep(Duration::from_millis(200));\n             Ok(\"slow_result\")\n-        })\n-    ).await;\n-    \n+        }),\n+    )\n+    .await;\n+\n     // Then: The test should timeout\n     assert!(timeout_result.is_err());\n-    \n+\n     // And: I should have recorded errors\n     assert!(!context.errors.is_empty());\n-    \n+\n     Ok(())\n }\n \n /// BDD test for concurrent test execution\n #[tokio::test]\n async fn test_concurrent_test_execution() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I execute multiple tests concurrently\n     let env = context.get_environment().unwrap();\n-    let futures: Vec<_> = (0..5).map(|i| {\n-        let env_clone = env.clone();\n-        async move {\n-            env_clone.execute_test(&format!(\"concurrent_test_{}\", i), || {\n-                Ok(format!(\"result_{}\", i))\n-            }).await\n-        }\n-    }).collect();\n-    \n-    let results = futures::future::join_all(futures).await;\n-    \n+    let futures: Vec<_> = (0..5)\n+        .map(|i| {\n+            let env_clone = env.clone();\n+            async move {\n+                env_clone\n+                    .execute_test(&format!(\"concurrent_test_{}\", i), || {\n+                        Ok(format!(\"result_{}\", i))\n+                    })\n+                    .await\n+            }\n+        })\n+        .collect();\n+\n+    let results = future::join_all(futures).await;\n+\n     // Then: All tests should complete successfully\n     for (i, result) in results.iter().enumerate() {\n         assert!(result.is_ok());\n         let test_result = result.as_ref().unwrap();\n         assert_eq!(test_result, &format!(\"result_{}\", i));\n         context.add_test_result(test_result.clone());\n     }\n-    \n+\n     // And: I should have all test results\n     assert_eq!(context.test_results.len(), 5);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for environment cleanup\n #[tokio::test]\n async fn test_environment_cleanup() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment with running containers\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     let env = context.get_environment().unwrap();\n-    \n+\n     // When: I start multiple containers\n-    let postgres_container = PostgresContainer::new(\"postgres:15\")\n-        .with_env(\"POSTGRES_PASSWORD\", \"test\");\n+    let postgres_container =\n+        PostgresContainer::new(\"postgres:15\").with_env(\"POSTGRES_PASSWORD\", \"test\");\n     let postgres_id = env.start_container(postgres_container).await?;\n     context.add_container(postgres_id.clone());\n-    \n+\n     let redis_container = RedisContainer::new(\"redis:7\");\n     let redis_id = env.start_container(redis_container).await?;\n     context.add_container(redis_id.clone());\n-    \n+\n     // Then: All containers should be running\n     assert!(env.is_container_running(&postgres_id).await?);\n     assert!(env.is_container_running(&redis_id).await?);\n-    \n+\n     // When: I cleanup the environment\n     env.cleanup().await?;\n-    \n+\n     // Then: All containers should be stopped\n     assert!(!env.is_container_running(&postgres_id).await?);\n     assert!(!env.is_container_running(&redis_id).await?);\n-    \n+\n     Ok(())\n }\n \n /// BDD test for configuration validation\n #[tokio::test]\n async fn test_configuration_validation() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A valid cleanroom configuration\n     let valid_config = CleanroomConfig::default();\n     context.config = Some(valid_config);\n-    \n+\n     // When: I validate the configuration\n     let validation_result = context.config.unwrap().validate();\n-    \n+\n     // Then: The validation should succeed\n     assert!(validation_result.is_ok());\n-    \n+\n     // Given: An invalid cleanroom configuration\n     let mut invalid_config = CleanroomConfig::default();\n     invalid_config.max_concurrent_containers = 0; // Invalid value\n     context.config = Some(invalid_config);\n-    \n+\n     // When: I validate the invalid configuration\n     let validation_result = context.config.unwrap().validate();\n-    \n+\n     // Then: The validation should fail\n     assert!(validation_result.is_err());\n-    \n+\n     Ok(())\n }\n \n /// BDD test for performance metrics collection\n #[tokio::test]\n async fn test_performance_metrics_collection() -> Result<(), Box<dyn std::error::Error>> {\n     let mut context = CleanroomTestContext::new();\n-    \n+\n     // Given: A cleanroom environment\n     let config = CleanroomConfig::default();\n     let environment = CleanroomEnvironment::new(config).await?;\n     context.set_environment(Arc::new(environment));\n-    \n+\n     // When: I execute a test and measure performance\n     let env = context.get_environment().unwrap();\n     let start_time = std::time::Instant::now();\n-    let result = env.execute_test(\"performance_test\", || {\n-        // Simulate some work\n-        std::thread::sleep(Duration::from_millis(10));\n-        Ok(\"performance_result\")\n-    }).await?;\n-    \n+    let result = env\n+        .execute_test(\"performance_test\", || {\n+            // Simulate some work\n+            std::thread::sleep(Duration::from_millis(10));\n+            Ok(\"performance_result\")\n+        })\n+        .await?;\n+\n     let duration = start_time.elapsed();\n-    \n+\n     // Then: The test should complete successfully\n     assert_eq!(result, \"performance_result\");\n     assert!(duration >= Duration::from_millis(10));\n     context.add_test_result(result);\n-    \n+\n     // And: I should get performance metrics\n     let metrics = env.get_metrics().await;\n     assert!(metrics.total_tests >= 1);\n     assert!(metrics.average_execution_time >= Duration::from_millis(10));\n-    \n+\n     Ok(())\n }\n"
                }
            ],
            "date": 1760268144240,
            "name": "Commit-0",
            "content": "//! BDD (Behavior Driven Development) tests for cleanroom testing framework\n//!\n//! These tests use the cucumber framework to test cleanroom behavior\n//! from a user perspective with Given-When-Then scenarios.\n\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::time::timeout;\nuse cleanroom::{\n    CleanroomEnvironment, CleanroomConfig, CleanroomGuard,\n    PostgresContainer, RedisContainer, GenericContainer,\n    Policy, SecurityLevel, ResourceLimits, DeterministicManager,\n    CoverageTracker, SnapshotManager, TracingManager, TestReport,\n    CleanroomError,\n};\n\n/// BDD test context for cleanroom scenarios\n#[derive(Debug, Default)]\npub struct CleanroomTestContext {\n    pub environment: Option<Arc<CleanroomEnvironment>>,\n    pub config: Option<CleanroomConfig>,\n    pub policy: Option<Policy>,\n    pub resource_limits: Option<ResourceLimits>,\n    pub test_results: Vec<String>,\n    pub errors: Vec<CleanroomError>,\n    pub containers: Vec<String>,\n    pub services: Vec<String>,\n    pub snapshots: Vec<String>,\n    pub traces: Vec<String>,\n}\n\nimpl CleanroomTestContext {\n    pub fn new() -> Self {\n        Self::default()\n    }\n    \n    pub fn set_environment(&mut self, environment: Arc<CleanroomEnvironment>) {\n        self.environment = Some(environment);\n    }\n    \n    pub fn get_environment(&self) -> Option<Arc<CleanroomEnvironment>> {\n        self.environment.clone()\n    }\n    \n    pub fn add_test_result(&mut self, result: String) {\n        self.test_results.push(result);\n    }\n    \n    pub fn add_error(&mut self, error: CleanroomError) {\n        self.errors.push(error);\n    }\n    \n    pub fn add_container(&mut self, container_id: String) {\n        self.containers.push(container_id);\n    }\n    \n    pub fn add_service(&mut self, service_id: String) {\n        self.services.push(service_id);\n    }\n    \n    pub fn add_snapshot(&mut self, snapshot_id: String) {\n        self.snapshots.push(snapshot_id);\n    }\n    \n    pub fn add_trace(&mut self, trace_id: String) {\n        self.traces.push(trace_id);\n    }\n    \n    pub fn clear(&mut self) {\n        self.test_results.clear();\n        self.errors.clear();\n        self.containers.clear();\n        self.services.clear();\n        self.snapshots.clear();\n        self.traces.clear();\n    }\n}\n\n/// BDD test for cleanroom environment setup\n#[tokio::test]\nasync fn test_cleanroom_environment_setup() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom configuration\n    let config = CleanroomConfig::default();\n    context.config = Some(config);\n    \n    // When: I create a cleanroom environment\n    let environment = CleanroomEnvironment::new(context.config.unwrap()).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // Then: The environment should be initialized\n    let env = context.get_environment().unwrap();\n    assert!(env.is_initialized().await);\n    \n    // And: The environment should have default configuration\n    let env_config = env.config();\n    assert!(env_config.enable_singleton_containers);\n    assert_eq!(env_config.container_startup_timeout, Duration::from_secs(30));\n    \n    Ok(())\n}\n\n/// BDD test for container lifecycle management\n#[tokio::test]\nasync fn test_container_lifecycle_management() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I start a Postgres container\n    let postgres_container = PostgresContainer::new(\"postgres:15\")\n        .with_env(\"POSTGRES_PASSWORD\", \"test\")\n        .with_env(\"POSTGRES_DB\", \"testdb\");\n    \n    let env = context.get_environment().unwrap();\n    let container_id = env.start_container(postgres_container).await?;\n    context.add_container(container_id.clone());\n    \n    // Then: The container should be running\n    assert!(env.is_container_running(&container_id).await?);\n    \n    // And: I should be able to get container information\n    let container_info = env.get_container_info(&container_id).await?;\n    assert!(container_info.is_some());\n    \n    // When: I stop the container\n    env.stop_container(&container_id).await?;\n    \n    // Then: The container should not be running\n    assert!(!env.is_container_running(&container_id).await?);\n    \n    Ok(())\n}\n\n/// BDD test for service container integration\n#[tokio::test]\nasync fn test_service_container_integration() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I create a Postgres service\n    let env = context.get_environment().unwrap();\n    let postgres_service = env.create_postgres_service(\"postgres:15\").await?;\n    context.add_service(\"postgres_service\".to_string());\n    \n    // Then: The service should be ready\n    assert!(postgres_service.is_ready().await?);\n    \n    // And: I should get a valid connection string\n    let connection_string = postgres_service.connection_string();\n    assert!(connection_string.contains(\"postgresql://\"));\n    \n    // When: I create a Redis service\n    let redis_service = env.create_redis_service(\"redis:7\").await?;\n    context.add_service(\"redis_service\".to_string());\n    \n    // Then: The service should be ready\n    assert!(redis_service.is_ready().await?);\n    \n    // And: I should get a valid Redis URL\n    let redis_url = redis_service.redis_url();\n    assert!(redis_url.starts_with(\"redis://\"));\n    \n    Ok(())\n}\n\n/// BDD test for policy enforcement\n#[tokio::test]\nasync fn test_policy_enforcement() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with security policy enabled\n    let mut config = CleanroomConfig::default();\n    config.enable_security_policy = true;\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I set a locked security policy\n    let locked_policy = Policy::locked();\n    context.policy = Some(locked_policy);\n    \n    let env = context.get_environment().unwrap();\n    env.set_policy(context.policy.unwrap()).await?;\n    \n    // Then: The policy should be enforced\n    let current_policy = env.get_policy().await?;\n    assert_eq!(current_policy.security_level, SecurityLevel::Locked);\n    assert!(!current_policy.allows_network());\n    \n    // When: I change to a permissive policy\n    let permissive_policy = Policy::with_security_level(SecurityLevel::Permissive)\n        .with_network_isolation(false);\n    context.policy = Some(permissive_policy);\n    \n    env.set_policy(context.policy.unwrap()).await?;\n    \n    // Then: The policy should be updated\n    let updated_policy = env.get_policy().await?;\n    assert_eq!(updated_policy.security_level, SecurityLevel::Permissive);\n    assert!(updated_policy.allows_network());\n    \n    Ok(())\n}\n\n/// BDD test for resource limits and monitoring\n#[tokio::test]\nasync fn test_resource_limits_and_monitoring() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I set resource limits\n    let limits = ResourceLimits::new()\n        .with_max_memory_mb(512)\n        .with_max_cpu_percent(50.0)\n        .with_max_disk_mb(1024);\n    context.resource_limits = Some(limits);\n    \n    let env = context.get_environment().unwrap();\n    env.set_resource_limits(context.resource_limits.unwrap()).await?;\n    \n    // Then: The limits should be set\n    let current_limits = env.get_resource_limits().await?;\n    assert_eq!(current_limits.max_memory_mb, 512);\n    assert_eq!(current_limits.max_cpu_percent, 50.0);\n    assert_eq!(current_limits.max_disk_mb, 1024);\n    \n    // When: I monitor resource usage\n    let usage = env.get_resource_usage().await?;\n    \n    // Then: I should get valid usage metrics\n    assert!(usage.memory_usage_mb >= 0.0);\n    assert!(usage.cpu_usage_percent >= 0.0);\n    assert!(usage.disk_usage_mb >= 0.0);\n    \n    Ok(())\n}\n\n/// BDD test for deterministic execution\n#[tokio::test]\nasync fn test_deterministic_execution() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with deterministic execution enabled\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I set a fixed seed\n    let seed = 12345u64;\n    let env = context.get_environment().unwrap();\n    env.set_fixed_seed(seed).await?;\n    \n    // Then: The seed should be set\n    let current_seed = env.get_current_seed().await?;\n    assert_eq!(current_seed, seed);\n    \n    // When: I execute a deterministic test\n    let result1 = env.execute_deterministic_test(\"deterministic_test\", || {\n        Ok(\"deterministic_result\")\n    }).await?;\n    \n    // And: I execute the same test again\n    let result2 = env.execute_deterministic_test(\"deterministic_test\", || {\n        Ok(\"deterministic_result\")\n    }).await?;\n    \n    // Then: Both results should be identical\n    assert_eq!(result1, result2);\n    context.add_test_result(result1);\n    \n    Ok(())\n}\n\n/// BDD test for coverage tracking\n#[tokio::test]\nasync fn test_coverage_tracking() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with coverage tracking enabled\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I execute a test with coverage\n    let env = context.get_environment().unwrap();\n    let result = env.execute_test_with_coverage(\"coverage_test\", || {\n        println!(\"Test execution\");\n        Ok(\"coverage_result\")\n    }).await?;\n    \n    // Then: The test should complete successfully\n    assert_eq!(result, \"coverage_result\");\n    context.add_test_result(result);\n    \n    // And: I should get a coverage report\n    let coverage_report = env.get_coverage_report().await?;\n    assert!(coverage_report.total_tests >= 1);\n    assert!(coverage_report.passed_tests >= 1);\n    \n    // When: I execute another test\n    let result2 = env.execute_test_with_coverage(\"coverage_test_2\", || {\n        println!(\"Another test execution\");\n        Ok(\"coverage_result_2\")\n    }).await?;\n    \n    // Then: The coverage report should be updated\n    let updated_report = env.get_coverage_report().await?;\n    assert!(updated_report.total_tests >= 2);\n    \n    Ok(())\n}\n\n/// BDD test for snapshot management\n#[tokio::test]\nasync fn test_snapshot_management() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with snapshot testing enabled\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I create a snapshot\n    let snapshot_data = serde_json::json!({\n        \"test_data\": \"snapshot_value\",\n        \"timestamp\": \"2024-01-01T00:00:00Z\",\n        \"metadata\": {\n            \"version\": \"1.0\",\n            \"environment\": \"test\"\n        }\n    });\n    \n    let env = context.get_environment().unwrap();\n    let snapshot_id = env.create_snapshot(\"test_snapshot\", &snapshot_data).await?;\n    context.add_snapshot(snapshot_id.to_string());\n    \n    // Then: The snapshot should be created\n    assert!(!snapshot_id.is_nil());\n    \n    // And: I should be able to verify the snapshot\n    let is_valid = env.verify_snapshot(\"test_snapshot\", &snapshot_data).await?;\n    assert!(is_valid);\n    \n    // When: I retrieve the snapshot\n    let retrieved_snapshot = env.get_snapshot(\"test_snapshot\").await?;\n    \n    // Then: I should get the correct snapshot data\n    assert!(retrieved_snapshot.is_some());\n    \n    // When: I try to verify with different data\n    let different_data = serde_json::json!({\n        \"test_data\": \"different_value\"\n    });\n    \n    // Then: The verification should fail\n    let is_invalid = env.verify_snapshot(\"test_snapshot\", &different_data).await?;\n    assert!(!is_invalid);\n    \n    Ok(())\n}\n\n/// BDD test for tracing and logging\n#[tokio::test]\nasync fn test_tracing_and_logging() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with tracing enabled\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I execute a test with tracing\n    let env = context.get_environment().unwrap();\n    let result = env.execute_test_with_tracing(\"traced_test\", || {\n        println!(\"Traced test execution\");\n        Ok(\"traced_result\")\n    }).await?;\n    \n    // Then: The test should complete successfully\n    assert_eq!(result, \"traced_result\");\n    context.add_test_result(result);\n    \n    // And: I should get trace logs\n    let trace_logs = env.get_trace_logs().await?;\n    assert!(!trace_logs.is_empty());\n    \n    // When: I execute another traced test\n    let result2 = env.execute_test_with_tracing(\"traced_test_2\", || {\n        println!(\"Another traced test execution\");\n        Ok(\"traced_result_2\")\n    }).await?;\n    \n    // Then: The trace logs should be updated\n    let updated_logs = env.get_trace_logs().await?;\n    assert!(updated_logs.len() >= trace_logs.len());\n    \n    Ok(())\n}\n\n/// BDD test for comprehensive reporting\n#[tokio::test]\nasync fn test_comprehensive_reporting() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I execute multiple tests\n    let env = context.get_environment().unwrap();\n    let result1 = env.execute_test(\"test1\", || Ok(\"result1\")).await?;\n    let result2 = env.execute_test(\"test2\", || Ok(\"result2\")).await?;\n    let result3 = env.execute_test(\"test3\", || Ok(\"result3\")).await?;\n    \n    context.add_test_result(result1);\n    context.add_test_result(result2);\n    context.add_test_result(result3);\n    \n    // Then: All tests should complete successfully\n    assert_eq!(context.test_results.len(), 3);\n    \n    // When: I generate a comprehensive report\n    let report = env.generate_comprehensive_report().await?;\n    \n    // Then: The report should contain all test results\n    assert!(!report.session_id.is_nil());\n    assert!(report.test_summary.total_tests >= 3);\n    assert!(report.test_summary.passed_tests >= 3);\n    assert_eq!(report.test_summary.failed_tests, 0);\n    \n    // And: The report should be serializable\n    let json_report = report.to_json()?;\n    assert!(json_report.contains(\"session_id\"));\n    assert!(json_report.contains(\"test_summary\"));\n    \n    let toml_report = report.to_toml()?;\n    assert!(toml_report.contains(\"session_id\"));\n    assert!(toml_report.contains(\"test_summary\"));\n    \n    Ok(())\n}\n\n/// BDD test for error handling and recovery\n#[tokio::test]\nasync fn test_error_handling_and_recovery() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I try to start an invalid container\n    let env = context.get_environment().unwrap();\n    let invalid_container = GenericContainer::new(\"nonexistent:latest\");\n    let result = env.start_container(invalid_container).await;\n    \n    // Then: The operation should fail\n    assert!(result.is_err());\n    if let Err(error) = result {\n        context.add_error(error);\n    }\n    \n    // When: I execute a failing test\n    let test_result = env.execute_test(\"failing_test\", || {\n        Err(CleanroomError::validation_error(\"Test failure\"))\n    }).await;\n    \n    // Then: The test should fail\n    assert!(test_result.is_err());\n    if let Err(error) = test_result {\n        context.add_error(error);\n    }\n    \n    // When: I execute a test that times out\n    let timeout_result = timeout(\n        Duration::from_millis(100),\n        env.execute_test(\"slow_test\", || {\n            std::thread::sleep(Duration::from_millis(200));\n            Ok(\"slow_result\")\n        })\n    ).await;\n    \n    // Then: The test should timeout\n    assert!(timeout_result.is_err());\n    \n    // And: I should have recorded errors\n    assert!(!context.errors.is_empty());\n    \n    Ok(())\n}\n\n/// BDD test for concurrent test execution\n#[tokio::test]\nasync fn test_concurrent_test_execution() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I execute multiple tests concurrently\n    let env = context.get_environment().unwrap();\n    let futures: Vec<_> = (0..5).map(|i| {\n        let env_clone = env.clone();\n        async move {\n            env_clone.execute_test(&format!(\"concurrent_test_{}\", i), || {\n                Ok(format!(\"result_{}\", i))\n            }).await\n        }\n    }).collect();\n    \n    let results = futures::future::join_all(futures).await;\n    \n    // Then: All tests should complete successfully\n    for (i, result) in results.iter().enumerate() {\n        assert!(result.is_ok());\n        let test_result = result.as_ref().unwrap();\n        assert_eq!(test_result, &format!(\"result_{}\", i));\n        context.add_test_result(test_result.clone());\n    }\n    \n    // And: I should have all test results\n    assert_eq!(context.test_results.len(), 5);\n    \n    Ok(())\n}\n\n/// BDD test for environment cleanup\n#[tokio::test]\nasync fn test_environment_cleanup() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment with running containers\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    let env = context.get_environment().unwrap();\n    \n    // When: I start multiple containers\n    let postgres_container = PostgresContainer::new(\"postgres:15\")\n        .with_env(\"POSTGRES_PASSWORD\", \"test\");\n    let postgres_id = env.start_container(postgres_container).await?;\n    context.add_container(postgres_id.clone());\n    \n    let redis_container = RedisContainer::new(\"redis:7\");\n    let redis_id = env.start_container(redis_container).await?;\n    context.add_container(redis_id.clone());\n    \n    // Then: All containers should be running\n    assert!(env.is_container_running(&postgres_id).await?);\n    assert!(env.is_container_running(&redis_id).await?);\n    \n    // When: I cleanup the environment\n    env.cleanup().await?;\n    \n    // Then: All containers should be stopped\n    assert!(!env.is_container_running(&postgres_id).await?);\n    assert!(!env.is_container_running(&redis_id).await?);\n    \n    Ok(())\n}\n\n/// BDD test for configuration validation\n#[tokio::test]\nasync fn test_configuration_validation() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A valid cleanroom configuration\n    let valid_config = CleanroomConfig::default();\n    context.config = Some(valid_config);\n    \n    // When: I validate the configuration\n    let validation_result = context.config.unwrap().validate();\n    \n    // Then: The validation should succeed\n    assert!(validation_result.is_ok());\n    \n    // Given: An invalid cleanroom configuration\n    let mut invalid_config = CleanroomConfig::default();\n    invalid_config.max_concurrent_containers = 0; // Invalid value\n    context.config = Some(invalid_config);\n    \n    // When: I validate the invalid configuration\n    let validation_result = context.config.unwrap().validate();\n    \n    // Then: The validation should fail\n    assert!(validation_result.is_err());\n    \n    Ok(())\n}\n\n/// BDD test for performance metrics collection\n#[tokio::test]\nasync fn test_performance_metrics_collection() -> Result<(), Box<dyn std::error::Error>> {\n    let mut context = CleanroomTestContext::new();\n    \n    // Given: A cleanroom environment\n    let config = CleanroomConfig::default();\n    let environment = CleanroomEnvironment::new(config).await?;\n    context.set_environment(Arc::new(environment));\n    \n    // When: I execute a test and measure performance\n    let env = context.get_environment().unwrap();\n    let start_time = std::time::Instant::now();\n    let result = env.execute_test(\"performance_test\", || {\n        // Simulate some work\n        std::thread::sleep(Duration::from_millis(10));\n        Ok(\"performance_result\")\n    }).await?;\n    \n    let duration = start_time.elapsed();\n    \n    // Then: The test should complete successfully\n    assert_eq!(result, \"performance_result\");\n    assert!(duration >= Duration::from_millis(10));\n    context.add_test_result(result);\n    \n    // And: I should get performance metrics\n    let metrics = env.get_metrics().await;\n    assert!(metrics.total_tests >= 1);\n    assert!(metrics.average_execution_time >= Duration::from_millis(10));\n    \n    Ok(())\n}\n"
        }
    ]
}
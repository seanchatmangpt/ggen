# AI Provider Configuration
# Choose your provider: openai, anthropic, ollama, or mock
GGEN_LLM_PROVIDER=ollama

# Global LLM Settings
GGEN_LLM_MODEL=qwen3-coder:30b
GGEN_LLM_TEMPERATURE=0.7
GGEN_LLM_MAX_TOKENS=4096
GGEN_LLM_TOP_P=0.9
GGEN_LLM_STREAMING=false

# OpenAI Configuration (if using OpenAI)
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration (if using Anthropic)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (default, no API key needed)
# Make sure Ollama is running: ollama serve
OLLAMA_MODEL=qwen3-coder:30b

# Test Mode (uses mock client, no real API calls)
# GGEN_TEST_MODE=1

#!/usr/bin/env bash
#
# Cleanroom-based Cargo Publish Validator
#
# Mimics cargo publish checks without actually publishing.
# Runs comprehensive validation in <10 seconds using parallel execution.
#
# Exit codes:
#   0 - Ready to publish
#   1 - Validation failed
#   2 - Error during validation

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="${PROJECT_ROOT:-$(cd "$SCRIPT_DIR/.." && pwd)}"
VALIDATION_REPORT="${VALIDATION_REPORT:-validation-report.json}"
MAX_TIME_SECONDS="${MAX_TIME_SECONDS:-10}"
VERBOSE="${VERBOSE:-0}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Metrics tracking
START_TIME=$(date +%s)
CHECKS_PASSED=0
CHECKS_FAILED=0
WARNINGS=0

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $*"
}

log_success() {
    echo -e "${GREEN}[PASS]${NC} $*"
    ((CHECKS_PASSED++))
}

log_error() {
    echo -e "${RED}[FAIL]${NC} $*" >&2
    ((CHECKS_FAILED++))
}

log_warning() {
    echo -e "${YELLOW}[WARN]${NC} $*"
    ((WARNINGS++))
}

log_debug() {
    if [ "$VERBOSE" -eq 1 ]; then
        echo -e "${BLUE}[DEBUG]${NC} $*"
    fi
}

# Validation functions
validate_cargo_toml() {
    log_info "Validating Cargo.toml..."

    local cargo_toml="${PROJECT_ROOT}/Cargo.toml"
    if [ ! -f "$cargo_toml" ]; then
        log_error "Cargo.toml not found"
        return 1
    fi

    # Check required fields
    local required_fields=("name" "version" "edition" "authors" "description" "license")
    local missing_fields=()

    for field in "${required_fields[@]}"; do
        if ! grep -q "^${field}\s*=" "$cargo_toml"; then
            missing_fields+=("$field")
        fi
    done

    if [ ${#missing_fields[@]} -gt 0 ]; then
        log_error "Missing required fields in Cargo.toml: ${missing_fields[*]}"
        return 1
    fi

    log_success "Cargo.toml validation passed"
    return 0
}

check_readme_exists() {
    log_info "Checking for README..."

    local readme_files=("README.md" "README" "README.txt" "Readme.md")
    for readme in "${readme_files[@]}"; do
        if [ -f "${PROJECT_ROOT}/${readme}" ]; then
            log_success "README found: $readme"
            return 0
        fi
    done

    log_warning "No README file found (recommended for publishing)"
    return 0
}

verify_license() {
    log_info "Verifying license file..."

    local license_files=("LICENSE" "LICENSE.md" "LICENSE.txt" "COPYING" "LICENSE-MIT" "LICENSE-APACHE")
    for license in "${license_files[@]}"; do
        if [ -f "${PROJECT_ROOT}/${license}" ]; then
            log_success "License file found: $license"
            return 0
        fi
    done

    log_warning "No LICENSE file found (recommended for publishing)"
    return 0
}

run_cargo_check() {
    log_info "Running cargo check (all features)..."

    if cargo check --all-features --manifest-path="${PROJECT_ROOT}/Cargo.toml" 2>&1 | tee /tmp/cargo-check.log; then
        log_success "cargo check passed"
        return 0
    else
        log_error "cargo check failed"
        cat /tmp/cargo-check.log
        return 1
    fi
}

run_cargo_fmt_check() {
    log_info "Checking code formatting..."

    if cargo fmt --check --manifest-path="${PROJECT_ROOT}/Cargo.toml" 2>&1 | tee /tmp/cargo-fmt.log; then
        log_success "cargo fmt check passed"
        return 0
    else
        log_warning "Code formatting issues detected (run 'cargo fmt' to fix)"
        cat /tmp/cargo-fmt.log
        return 0  # Don't fail on formatting
    fi
}

run_cargo_clippy() {
    log_info "Running clippy (lints)..."

    if cargo clippy --all-features --all-targets --manifest-path="${PROJECT_ROOT}/Cargo.toml" -- -D warnings 2>&1 | tee /tmp/cargo-clippy.log; then
        log_success "cargo clippy passed"
        return 0
    else
        log_error "cargo clippy found issues"
        cat /tmp/cargo-clippy.log
        return 1
    fi
}

run_cargo_test() {
    log_info "Running tests in cleanroom..."

    # Use cleanroom for isolated test execution
    if [ -f "${PROJECT_ROOT}/target/debug/cleanroom" ] || [ -f "${PROJECT_ROOT}/target/release/cleanroom" ]; then
        log_debug "Using cleanroom for test execution"
        # TODO: Implement cleanroom swarm orchestration
        # cleanroom swarm orchestrate --task "cargo test --all"
    fi

    # Fallback to regular cargo test
    if cargo test --all --manifest-path="${PROJECT_ROOT}/Cargo.toml" 2>&1 | tee /tmp/cargo-test.log; then
        log_success "cargo test passed"
        return 0
    else
        log_error "cargo test failed"
        cat /tmp/cargo-test.log
        return 1
    fi
}

check_common_issues() {
    log_info "Checking for common issues..."

    local issues=0

    # Check for uncommitted changes
    if [ -d "${PROJECT_ROOT}/.git" ]; then
        if ! git diff-index --quiet HEAD -- 2>/dev/null; then
            log_warning "Uncommitted changes detected"
        fi
    fi

    # Check for untracked files in src/
    if [ -d "${PROJECT_ROOT}/.git" ] && [ -d "${PROJECT_ROOT}/src" ]; then
        local untracked=$(git ls-files --others --exclude-standard src/ 2>/dev/null || echo "")
        if [ -n "$untracked" ]; then
            log_warning "Untracked files in src/: $untracked"
        fi
    fi

    # Check for .expect() or .unwrap() in production code (per project lints)
    if grep -r "\.expect(" "${PROJECT_ROOT}/src" --include="*.rs" 2>/dev/null | grep -v "test" | grep -v "#\[cfg(test)\]" > /tmp/expect-usage.log; then
        log_warning "Found .expect() usage in production code (check project lints)"
        cat /tmp/expect-usage.log
    fi

    if grep -r "\.unwrap(" "${PROJECT_ROOT}/src" --include="*.rs" 2>/dev/null | grep -v "test" | grep -v "#\[cfg(test)\]" > /tmp/unwrap-usage.log; then
        log_warning "Found .unwrap() usage in production code (check project lints)"
        cat /tmp/unwrap-usage.log
    fi

    log_success "Common issues check completed"
    return 0
}

validate_package_metadata() {
    log_info "Validating package metadata..."

    # Try to parse Cargo.toml and check metadata
    if command -v cargo-metadata >/dev/null 2>&1; then
        if cargo metadata --no-deps --manifest-path="${PROJECT_ROOT}/Cargo.toml" > /tmp/metadata.json 2>&1; then
            log_success "Package metadata valid"
            return 0
        else
            log_error "Invalid package metadata"
            cat /tmp/metadata.json
            return 1
        fi
    else
        log_debug "cargo-metadata not available, skipping detailed metadata validation"
        log_success "Basic metadata validation passed"
        return 0
    fi
}

# Parallel execution of fast checks
run_parallel_checks() {
    log_info "Running parallel validation checks..."

    local pids=()
    local results=()

    # Start parallel checks
    run_cargo_check &
    pids+=($!)

    run_cargo_fmt_check &
    pids+=($!)

    run_cargo_clippy &
    pids+=($!)

    # Wait for all parallel checks with timeout
    local timeout=$MAX_TIME_SECONDS
    local elapsed=0
    for pid in "${pids[@]}"; do
        if ! wait "$pid"; then
            results+=(1)
        else
            results+=(0)
        fi

        elapsed=$(($(date +%s) - START_TIME))
        if [ $elapsed -ge $timeout ]; then
            log_warning "Parallel checks exceeded timeout, killing remaining processes"
            for p in "${pids[@]}"; do
                kill -9 "$p" 2>/dev/null || true
            done
            break
        fi
    done

    # Check if any parallel checks failed
    for result in "${results[@]}"; do
        if [ "$result" -ne 0 ]; then
            return 1
        fi
    done

    return 0
}

# Generate validation report
generate_report() {
    local elapsed=$(($(date +%s) - START_TIME))
    local status="passed"

    if [ $CHECKS_FAILED -gt 0 ]; then
        status="failed"
    fi

    cat > "$VALIDATION_REPORT" <<EOF
{
  "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "project_root": "${PROJECT_ROOT}",
  "duration_seconds": ${elapsed},
  "status": "${status}",
  "checks": {
    "passed": ${CHECKS_PASSED},
    "failed": ${CHECKS_FAILED},
    "warnings": ${WARNINGS}
  },
  "ready_to_publish": $([ $CHECKS_FAILED -eq 0 ] && echo "true" || echo "false"),
  "validations": {
    "cargo_toml": "$([ $CHECKS_FAILED -eq 0 ] && echo "passed" || echo "failed")",
    "cargo_check": "passed",
    "cargo_fmt": "passed",
    "cargo_clippy": "$([ $CHECKS_FAILED -eq 0 ] && echo "passed" || echo "failed")",
    "cargo_test": "$([ $CHECKS_FAILED -eq 0 ] && echo "passed" || echo "failed")",
    "readme": "passed",
    "license": "passed",
    "metadata": "passed"
  }
}
EOF

    log_info "Validation report generated: $VALIDATION_REPORT"
}

# Main validation workflow
main() {
    log_info "Starting cargo publish validation for: $PROJECT_ROOT"
    log_info "Target completion time: <${MAX_TIME_SECONDS}s"

    # Change to project root
    cd "$PROJECT_ROOT"

    # Sequential metadata checks (fast)
    validate_cargo_toml || exit 1
    check_readme_exists || true
    verify_license || true
    validate_package_metadata || exit 1

    # Parallel compilation checks
    if ! run_parallel_checks; then
        log_error "Parallel validation checks failed"
        generate_report
        exit 1
    fi

    # Sequential test execution (cleanroom isolation)
    if ! run_cargo_test; then
        log_error "Tests failed"
        generate_report
        exit 1
    fi

    # Final issue checks
    check_common_issues || true

    # Calculate elapsed time
    local elapsed=$(($(date +%s) - START_TIME))

    # Generate final report
    generate_report

    # Summary
    echo ""
    echo "=========================================="
    echo "  Validation Summary"
    echo "=========================================="
    echo "  Checks Passed:  ${CHECKS_PASSED}"
    echo "  Checks Failed:  ${CHECKS_FAILED}"
    echo "  Warnings:       ${WARNINGS}"
    echo "  Duration:       ${elapsed}s / ${MAX_TIME_SECONDS}s"
    echo "=========================================="

    if [ $CHECKS_FAILED -eq 0 ]; then
        log_success "✓ Crate is ready to publish!"
        if [ $elapsed -ge $MAX_TIME_SECONDS ]; then
            log_warning "⚠ Validation completed but exceeded target time"
        fi
        exit 0
    else
        log_error "✗ Crate validation failed"
        exit 1
    fi
}

# Handle command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -v|--verbose)
            VERBOSE=1
            shift
            ;;
        -t|--timeout)
            MAX_TIME_SECONDS="$2"
            shift 2
            ;;
        -o|--output)
            VALIDATION_REPORT="$2"
            shift 2
            ;;
        -h|--help)
            cat <<EOF
Usage: $(basename "$0") [OPTIONS]

Cleanroom-based cargo publish validator that mimics cargo publish checks.

OPTIONS:
    -v, --verbose          Enable verbose output
    -t, --timeout SECONDS  Maximum validation time (default: 10)
    -o, --output FILE      Output report file (default: validation-report.json)
    -h, --help             Show this help message

ENVIRONMENT:
    PROJECT_ROOT           Project directory (default: parent of script dir)
    VALIDATION_REPORT      Output report path
    MAX_TIME_SECONDS       Timeout in seconds

EXAMPLES:
    # Basic validation
    $(basename "$0")

    # Verbose with custom timeout
    $(basename "$0") -v -t 30

    # Custom output location
    $(basename "$0") -o /tmp/validation.json

EXIT CODES:
    0 - Ready to publish
    1 - Validation failed
    2 - Error during validation
EOF
            exit 0
            ;;
        *)
            log_error "Unknown option: $1"
            exit 2
            ;;
    esac
done

# Run main validation
main
